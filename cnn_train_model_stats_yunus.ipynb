{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cnn_train.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RMUVEPs5GBfD",
        "7Njs0Z49aLb-",
        "rlh8lxRevAje"
      ],
      "mount_file_id": "1bKCP2YXLqn4gSnvSbRih0W4i5q987ohD",
      "authorship_tag": "ABX9TyPq+dXA7CESDZtYOE3Vac3a",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YunusKaratepe/duygu-tanima/blob/main/cnn_train_model_stats_yunus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zTCT376Fy7H"
      },
      "source": [
        "# Import drive and arrange path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O68bTzOjGUn7",
        "outputId": "6baf467d-0dd9-4bb8-a0ee-84c681afe2d4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUriPVZqEupb",
        "outputId": "9df0eb6a-84ec-4195-fb89-3305cf037cdc"
      },
      "source": [
        "%cd /content/drive/MyDrive/colab/final_project"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/colab/final_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gCUJJ5gxFWaJ",
        "outputId": "c50c9051-030d-470c-8575-083fa836b097"
      },
      "source": [
        "%pwd # displays current path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/colab/final_project'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMUVEPs5GBfD"
      },
      "source": [
        "# Import libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhPrn2oDFjjD"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization\n",
        "from keras.layers import Dropout, Flatten, Conv2D, MaxPooling2D, Activation\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import activations"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iIaiCdX6Y0s",
        "outputId": "1d51e760-b379-4d3d-fb90-08353417a4b0"
      },
      "source": [
        "# checking gpu device\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 18246028955128570486, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14509932544\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 12514682585921123519\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAik2giqGhcp"
      },
      "source": [
        "# Get data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL3azXD9GuB2"
      },
      "source": [
        "My data paths:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20AFNAT6GxfV"
      },
      "source": [
        "linear_path = './spec_data/LinearSpectrogram/LinearSpectrogramOriginal/'\n",
        "linear_augNormal_path = './spec_data/LinearSpectrogram/LinearSpectrogram_AugNormal/'\n",
        "linear_augDerivative1_path = './spec_data/LinearSpectrogram/LinearSpectrogram_AugDerivativeOrder1/'\n",
        "linear_augDerivative2_path = './spec_data/LinearSpectrogram/LinearSpectrogram_AugDerivativeOrder2/'\n",
        "\n",
        "log_path = './spec_data/LogSpectrogram/LogSpectrogramOriginal/'\n",
        "log_augNormal_path = './spec_data/LogSpectrogram/LogSpectrogram_AugNormal/'\n",
        "log_augDerivative1_path = './spec_data/LogSpectrogram/LogSpectrogram_AugDerivativeOrder1/' \n",
        "log_augDerivative2_path = './spec_data/LogSpectrogram/LogSpectrogram_AugDerivativeOrder2/'\n",
        "\n",
        "mel128_augNormal = '/spec_data/MelSpectrogram128'\n"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Afi8ix_gGg-g"
      },
      "source": [
        "def getDataset(directory: str, seed: int): \n",
        "\n",
        "  train_set=tf.keras.preprocessing.image_dataset_from_directory(\n",
        "      directory,\n",
        "      labels=\"inferred\",\n",
        "      label_mode=\"categorical\",\n",
        "      subset=\"training\",\n",
        "      class_names=None,\n",
        "      shuffle=True,\n",
        "      seed = seed, #10 50 100 verecegiz \n",
        "      batch_size=32,\n",
        "      image_size=(128, 128),\n",
        "      validation_split = 0.2,\n",
        "      #interpolation=\"lanczos5\"\n",
        "  )\n",
        "\n",
        "  test_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "      directory,\n",
        "      labels=\"inferred\",\n",
        "      label_mode=\"categorical\",\n",
        "      subset=\"validation\",\n",
        "      validation_split = 0.2,\n",
        "      class_names=None,\n",
        "      shuffle=True,\n",
        "      seed = seed, #10 50 100 verecegiz\n",
        "      batch_size=32,\n",
        "      image_size=(128, 128),\n",
        "      #interpolation=\"lanczos5\"\n",
        "  )\n",
        "  #print(test_set)\n",
        "  #for data, labels in test_set:\n",
        "    #print(data.shape)  # (64, 200, 200, 3)\n",
        "  return train_set, test_set"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Njs0Z49aLb-"
      },
      "source": [
        "# Training of custom CNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vfk-P0RnDecH"
      },
      "source": [
        "0.59 max başarı, 20 epoch'ta acc=1.0 ->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA8kig0WaIIk"
      },
      "source": [
        "# def trainCustomCNN(train_set, test_set):\n",
        "#   X_train  = train_set\n",
        "#   opt  = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "\n",
        "#   model = keras.Sequential() \n",
        "  \n",
        "#   model.add(keras.layers.Conv2D(128, input_shape=(128,72,3), kernel_size=80, strides=4, padding='same', kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(l=0.0001)))\n",
        "#   model.add(keras.layers.BatchNormalization())\n",
        "#   model.add(keras.layers.Activation('relu'))\n",
        "#   model.add(keras.layers.MaxPooling2D(pool_size=4, strides=None, padding='same'))\n",
        "\n",
        "#   model.add(keras.layers.Conv2D(128, kernel_size=3, strides=1, padding='same', kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(l=0.0001)))\n",
        "#   model.add(keras.layers.BatchNormalization())\n",
        "#   model.add(keras.layers.Activation('relu'))\n",
        "#   model.add(keras.layers.MaxPooling2D(pool_size=2, strides=None, padding='same'))\n",
        "\n",
        "#   model.add(keras.layers.Conv2D(256, kernel_size=3, strides=1, padding='same', kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(l=0.0001)))\n",
        "#   model.add(keras.layers.BatchNormalization())\n",
        "#   model.add(keras.layers.Activation('relu'))\n",
        "#   model.add(keras.layers.MaxPooling2D(pool_size=2, strides=None, padding='same'))\n",
        "\n",
        "#   model.add(keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(l=0.0001)))\n",
        "#   model.add(keras.layers.BatchNormalization())\n",
        "#   model.add(keras.layers.Activation('relu'))\n",
        "#   model.add(keras.layers.MaxPooling2D(pool_size=2, strides=None, padding='same'))\n",
        "\n",
        "\n",
        "#   model.add(keras.layers.Lambda(lambda x : keras.backend.mean(x, axis=1)))\n",
        "#   model.add(keras.layers.Lambda(lambda x : keras.backend.mean(x, axis=1)))\n",
        "#   model.add(keras.layers.Dense(8, activation='softmax'))\n",
        "\n",
        "#   model.compile(optimizer = opt, loss='categorical_crossentropy',metrics = ['accuracy', keras.metrics.TruePositives(), keras.metrics.TrueNegatives(), keras.metrics.FalsePositives(), keras.metrics.FalseNegatives()]) \n",
        "#   model.summary()  \n",
        "#   model.fit(x = X_train, validation_data = test_set, epochs = 50)\n",
        "#   model.save('./models/my_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF39C_4RMl8u"
      },
      "source": [
        "Ahmetlerin modeli, başarı düşük ->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RFbv5fRzoVb"
      },
      "source": [
        "# def trainCustomCNN(train_set, test_set, numof_classes):\n",
        "\n",
        "#     model = keras.Sequential()\n",
        "#     # LFLB1\n",
        "#     model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', data_format='channels_last',input_shape=(128,128,3)))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(Activation('elu'))\n",
        "#     model.add(MaxPooling2D(pool_size=(4,4), strides=(2,2)))\n",
        "#     model.add(Dropout(0.5))\n",
        "\n",
        "#     model.add(Conv2D(filters=128,kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(Activation('elu'))\n",
        "#     model.add(MaxPooling2D(pool_size=(2,2), strides=(4,4)))\n",
        "#     model.add(Dropout(0.25))\n",
        "\n",
        "#     model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(Activation('elu'))\n",
        "#     model.add(MaxPooling2D(pool_size=(2,2), strides=(4,4)))\n",
        "#     model.add(Dropout(0.25))\n",
        "\n",
        "#     model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(Activation('elu'))\n",
        "#     model.add(MaxPooling2D(pool_size=(2,2), strides=(4,4)))\n",
        "#     model.add(Dropout(0.25))\n",
        "\n",
        "#     model.add(Flatten())\n",
        "#     # FC\n",
        "#     model.add(Dense(8, activation='softmax'))\n",
        "\n",
        "#     # Model compilation\n",
        "#     opt = optimizers.Adam(lr=0.001, beta_1=0.9,  beta_2=0.999, amsgrad=False)\n",
        "#     model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy', keras.metrics.FalsePositives()])\n",
        "#     model.summary()\n",
        "#     model.fit(x = train_set, validation_data = test_set, epochs = 100)\n",
        "#     model.save('./models/ahmet_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcrC_D3-MhHW"
      },
      "source": [
        "En başarılı model ->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_D0wE1lDaw3"
      },
      "source": [
        "def trainCustomCNN(train_set, test_set, numof_classes, specType, seed):\n",
        "    X_train  = train_set\n",
        "    opt  = tf.keras.optimizers.Adam(learning_rate=0.00005)\n",
        "\n",
        "    #input_shape=(128, 128),\n",
        "    model = keras.Sequential() \n",
        "\n",
        "    model.add(keras.layers.Conv2D(64, input_shape=(128, 128, 3), kernel_size=(3,3), strides=(1,1), padding='same', kernel_regularizer=keras.regularizers.l2(l=0.0005)))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Activation('relu'))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=4, strides=None, padding='same'))\n",
        "\n",
        "    model.add(keras.layers.Conv2D(64, kernel_size=(3,3), strides=1, padding='same', kernel_regularizer=keras.regularizers.l2(l=0.0005)))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Activation('relu'))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=2, strides=None, padding='same'))\n",
        "\n",
        "    model.add(keras.layers.Conv2D(128, kernel_size=(3,3), strides=1, padding='same', kernel_regularizer=keras.regularizers.l2(l=0.0005)))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Activation('relu'))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=2, strides=None, padding='same'))\n",
        "\n",
        "    model.add(keras.layers.Conv2D(128, kernel_size=(3,3), strides=1, padding='same', kernel_regularizer=keras.regularizers.l2(l=0.0005)))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Activation('relu'))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=2, strides=None, padding='same'))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(keras.layers.Dense(numof_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer = opt, loss='categorical_crossentropy', metrics = ['accuracy', keras.metrics.FalsePositives()]) \n",
        "    model.summary()\n",
        "    model.fit(x = X_train, validation_data = test_set, epochs = 100)\n",
        "    model.save('./models/seed' + str(seed) + '/'  + specType + '.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRKlVGV_Fucg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18ebcb52-dca3-4a9a-db4c-ebe108f9d24d"
      },
      "source": [
        "train_set, test_set = getDataset(linear_augDerivative2_path, seed=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2880 files belonging to 8 classes.\n",
            "Using 2304 files for training.\n",
            "Found 2880 files belonging to 8 classes.\n",
            "Using 576 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWJrZdKNa5dq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecdfca64-c121-4d61-f731-e1669de6eeeb"
      },
      "source": [
        "trainCustomCNN(train_set, test_set, numof_classes=8, specType='mel128_specAugment', seed=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 128, 128, 64)      1792      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 128, 128, 64)      256       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 4104      \n",
            "=================================================================\n",
            "Total params: 1,316,936\n",
            "Trainable params: 1,315,144\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "72/72 [==============================] - 389s 4s/step - loss: 2.9506 - accuracy: 0.1727 - false_positives: 433.9041 - val_loss: 2.6410 - val_accuracy: 0.1632 - val_false_positives: 33.0000\n",
            "Epoch 2/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 2.3617 - accuracy: 0.2629 - false_positives: 379.3699 - val_loss: 2.1565 - val_accuracy: 0.2396 - val_false_positives: 43.0000\n",
            "Epoch 3/100\n",
            "72/72 [==============================] - 42s 530ms/step - loss: 2.1768 - accuracy: 0.3167 - false_positives: 343.3836 - val_loss: 1.9171 - val_accuracy: 0.3403 - val_false_positives: 35.0000\n",
            "Epoch 4/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 2.0850 - accuracy: 0.3414 - false_positives: 342.5205 - val_loss: 1.8731 - val_accuracy: 0.3420 - val_false_positives: 81.0000\n",
            "Epoch 5/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 1.9197 - accuracy: 0.3952 - false_positives: 317.9589 - val_loss: 1.7862 - val_accuracy: 0.3785 - val_false_positives: 80.0000\n",
            "Epoch 6/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 1.8287 - accuracy: 0.4053 - false_positives: 323.6849 - val_loss: 1.8175 - val_accuracy: 0.3646 - val_false_positives: 114.0000\n",
            "Epoch 7/100\n",
            "72/72 [==============================] - 42s 530ms/step - loss: 1.7685 - accuracy: 0.4216 - false_positives: 312.6301 - val_loss: 1.7270 - val_accuracy: 0.4306 - val_false_positives: 95.0000\n",
            "Epoch 8/100\n",
            "72/72 [==============================] - 42s 530ms/step - loss: 1.6845 - accuracy: 0.4671 - false_positives: 288.0274 - val_loss: 1.7099 - val_accuracy: 0.4288 - val_false_positives: 107.0000\n",
            "Epoch 9/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 1.5445 - accuracy: 0.4893 - false_positives: 253.0822 - val_loss: 1.7875 - val_accuracy: 0.3976 - val_false_positives: 135.0000\n",
            "Epoch 10/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 1.4824 - accuracy: 0.5119 - false_positives: 279.1918 - val_loss: 1.6651 - val_accuracy: 0.4688 - val_false_positives: 111.0000\n",
            "Epoch 11/100\n",
            "72/72 [==============================] - 42s 533ms/step - loss: 1.3817 - accuracy: 0.5617 - false_positives: 249.6712 - val_loss: 1.7363 - val_accuracy: 0.4497 - val_false_positives: 123.0000\n",
            "Epoch 12/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 1.3209 - accuracy: 0.5845 - false_positives: 228.3151 - val_loss: 1.6457 - val_accuracy: 0.4670 - val_false_positives: 131.0000\n",
            "Epoch 13/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 1.2424 - accuracy: 0.6082 - false_positives: 208.9452 - val_loss: 1.6815 - val_accuracy: 0.4653 - val_false_positives: 127.0000\n",
            "Epoch 14/100\n",
            "72/72 [==============================] - 43s 548ms/step - loss: 1.1820 - accuracy: 0.6316 - false_positives: 208.0548 - val_loss: 1.6052 - val_accuracy: 0.4549 - val_false_positives: 140.0000\n",
            "Epoch 15/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 1.0938 - accuracy: 0.6529 - false_positives: 200.5205 - val_loss: 1.5664 - val_accuracy: 0.4705 - val_false_positives: 127.0000\n",
            "Epoch 16/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 1.0870 - accuracy: 0.6551 - false_positives: 194.6438 - val_loss: 1.6664 - val_accuracy: 0.4497 - val_false_positives: 145.0000\n",
            "Epoch 17/100\n",
            "72/72 [==============================] - 42s 536ms/step - loss: 0.9854 - accuracy: 0.6956 - false_positives: 165.8904 - val_loss: 1.5793 - val_accuracy: 0.4809 - val_false_positives: 138.0000\n",
            "Epoch 18/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.9956 - accuracy: 0.7100 - false_positives: 168.3151 - val_loss: 1.5697 - val_accuracy: 0.4931 - val_false_positives: 139.0000\n",
            "Epoch 19/100\n",
            "72/72 [==============================] - 42s 533ms/step - loss: 0.9149 - accuracy: 0.7292 - false_positives: 162.2329 - val_loss: 1.5507 - val_accuracy: 0.4983 - val_false_positives: 145.0000\n",
            "Epoch 20/100\n",
            "72/72 [==============================] - 42s 536ms/step - loss: 0.8882 - accuracy: 0.7543 - false_positives: 143.6164 - val_loss: 1.5725 - val_accuracy: 0.5035 - val_false_positives: 155.0000\n",
            "Epoch 21/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.8165 - accuracy: 0.7679 - false_positives: 128.7123 - val_loss: 1.5563 - val_accuracy: 0.4948 - val_false_positives: 165.0000\n",
            "Epoch 22/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.7584 - accuracy: 0.8041 - false_positives: 120.8356 - val_loss: 1.6033 - val_accuracy: 0.4844 - val_false_positives: 180.0000\n",
            "Epoch 23/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.7136 - accuracy: 0.8148 - false_positives: 118.4932 - val_loss: 1.5227 - val_accuracy: 0.5139 - val_false_positives: 162.0000\n",
            "Epoch 24/100\n",
            "72/72 [==============================] - 42s 538ms/step - loss: 0.6581 - accuracy: 0.8398 - false_positives: 105.7123 - val_loss: 1.5669 - val_accuracy: 0.5278 - val_false_positives: 154.0000\n",
            "Epoch 25/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.6464 - accuracy: 0.8342 - false_positives: 94.3014 - val_loss: 1.5117 - val_accuracy: 0.4965 - val_false_positives: 168.0000\n",
            "Epoch 26/100\n",
            "72/72 [==============================] - 42s 539ms/step - loss: 0.5905 - accuracy: 0.8618 - false_positives: 79.6986 - val_loss: 1.5506 - val_accuracy: 0.5052 - val_false_positives: 163.0000\n",
            "Epoch 27/100\n",
            "72/72 [==============================] - 43s 550ms/step - loss: 0.5468 - accuracy: 0.8811 - false_positives: 70.3014 - val_loss: 1.5506 - val_accuracy: 0.5104 - val_false_positives: 169.0000\n",
            "Epoch 28/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.5345 - accuracy: 0.8779 - false_positives: 79.0000 - val_loss: 1.5204 - val_accuracy: 0.5017 - val_false_positives: 178.0000\n",
            "Epoch 29/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.5110 - accuracy: 0.8986 - false_positives: 69.6986 - val_loss: 1.4871 - val_accuracy: 0.5382 - val_false_positives: 165.0000\n",
            "Epoch 30/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.5121 - accuracy: 0.8856 - false_positives: 71.3699 - val_loss: 1.5572 - val_accuracy: 0.5243 - val_false_positives: 160.0000\n",
            "Epoch 31/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.4756 - accuracy: 0.9028 - false_positives: 50.5342 - val_loss: 1.5229 - val_accuracy: 0.5365 - val_false_positives: 166.0000\n",
            "Epoch 32/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 0.4112 - accuracy: 0.9325 - false_positives: 43.2603 - val_loss: 1.5749 - val_accuracy: 0.5122 - val_false_positives: 179.0000\n",
            "Epoch 33/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.4086 - accuracy: 0.9359 - false_positives: 47.2192 - val_loss: 1.4527 - val_accuracy: 0.5608 - val_false_positives: 150.0000\n",
            "Epoch 34/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.4049 - accuracy: 0.9245 - false_positives: 45.7260 - val_loss: 1.5312 - val_accuracy: 0.5208 - val_false_positives: 183.0000\n",
            "Epoch 35/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.3713 - accuracy: 0.9431 - false_positives: 31.6027 - val_loss: 1.6377 - val_accuracy: 0.5156 - val_false_positives: 172.0000\n",
            "Epoch 36/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.3567 - accuracy: 0.9576 - false_positives: 28.0959 - val_loss: 1.5890 - val_accuracy: 0.5365 - val_false_positives: 181.0000\n",
            "Epoch 37/100\n",
            "72/72 [==============================] - 41s 528ms/step - loss: 0.3171 - accuracy: 0.9675 - false_positives: 20.5342 - val_loss: 1.4690 - val_accuracy: 0.5434 - val_false_positives: 175.0000\n",
            "Epoch 38/100\n",
            "72/72 [==============================] - 42s 530ms/step - loss: 0.3277 - accuracy: 0.9594 - false_positives: 29.1781 - val_loss: 1.5074 - val_accuracy: 0.5538 - val_false_positives: 179.0000\n",
            "Epoch 39/100\n",
            "72/72 [==============================] - 42s 530ms/step - loss: 0.3280 - accuracy: 0.9570 - false_positives: 32.5068 - val_loss: 1.5343 - val_accuracy: 0.5451 - val_false_positives: 183.0000\n",
            "Epoch 40/100\n",
            "72/72 [==============================] - 42s 533ms/step - loss: 0.3133 - accuracy: 0.9646 - false_positives: 23.8767 - val_loss: 1.4809 - val_accuracy: 0.5573 - val_false_positives: 177.0000\n",
            "Epoch 41/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.2821 - accuracy: 0.9754 - false_positives: 16.9863 - val_loss: 1.5418 - val_accuracy: 0.5399 - val_false_positives: 181.0000\n",
            "Epoch 42/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 0.2778 - accuracy: 0.9781 - false_positives: 18.6712 - val_loss: 1.5028 - val_accuracy: 0.5434 - val_false_positives: 176.0000\n",
            "Epoch 43/100\n",
            "72/72 [==============================] - 41s 529ms/step - loss: 0.2795 - accuracy: 0.9704 - false_positives: 21.0411 - val_loss: 1.5029 - val_accuracy: 0.5503 - val_false_positives: 173.0000\n",
            "Epoch 44/100\n",
            "72/72 [==============================] - 42s 529ms/step - loss: 0.2603 - accuracy: 0.9831 - false_positives: 13.2466 - val_loss: 1.5779 - val_accuracy: 0.5191 - val_false_positives: 201.0000\n",
            "Epoch 45/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 0.2538 - accuracy: 0.9796 - false_positives: 13.9315 - val_loss: 1.5891 - val_accuracy: 0.5347 - val_false_positives: 201.0000\n",
            "Epoch 46/100\n",
            "72/72 [==============================] - 41s 529ms/step - loss: 0.2413 - accuracy: 0.9878 - false_positives: 9.0685 - val_loss: 1.6274 - val_accuracy: 0.5122 - val_false_positives: 203.0000\n",
            "Epoch 47/100\n",
            "72/72 [==============================] - 42s 530ms/step - loss: 0.2517 - accuracy: 0.9778 - false_positives: 17.2603 - val_loss: 1.5930 - val_accuracy: 0.5382 - val_false_positives: 199.0000\n",
            "Epoch 48/100\n",
            "72/72 [==============================] - 41s 529ms/step - loss: 0.2371 - accuracy: 0.9835 - false_positives: 17.1918 - val_loss: 1.5702 - val_accuracy: 0.5243 - val_false_positives: 207.0000\n",
            "Epoch 49/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 0.2205 - accuracy: 0.9904 - false_positives: 7.3425 - val_loss: 1.5807 - val_accuracy: 0.5486 - val_false_positives: 192.0000\n",
            "Epoch 50/100\n",
            "72/72 [==============================] - 41s 529ms/step - loss: 0.2193 - accuracy: 0.9897 - false_positives: 7.1096 - val_loss: 1.6094 - val_accuracy: 0.5347 - val_false_positives: 194.0000\n",
            "Epoch 51/100\n",
            "72/72 [==============================] - 41s 528ms/step - loss: 0.2437 - accuracy: 0.9805 - false_positives: 9.3151 - val_loss: 1.6393 - val_accuracy: 0.5330 - val_false_positives: 195.0000\n",
            "Epoch 52/100\n",
            "72/72 [==============================] - 43s 554ms/step - loss: 0.2190 - accuracy: 0.9863 - false_positives: 7.1096 - val_loss: 1.5707 - val_accuracy: 0.5538 - val_false_positives: 188.0000\n",
            "Epoch 53/100\n",
            "72/72 [==============================] - 42s 538ms/step - loss: 0.2053 - accuracy: 0.9894 - false_positives: 8.0822 - val_loss: 1.5381 - val_accuracy: 0.5486 - val_false_positives: 186.0000\n",
            "Epoch 54/100\n",
            "72/72 [==============================] - 41s 528ms/step - loss: 0.2058 - accuracy: 0.9923 - false_positives: 7.2603 - val_loss: 1.6036 - val_accuracy: 0.5469 - val_false_positives: 188.0000\n",
            "Epoch 55/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.2033 - accuracy: 0.9933 - false_positives: 2.9863 - val_loss: 1.6440 - val_accuracy: 0.5260 - val_false_positives: 203.0000\n",
            "Epoch 56/100\n",
            "72/72 [==============================] - 42s 530ms/step - loss: 0.1948 - accuracy: 0.9934 - false_positives: 6.7671 - val_loss: 1.6452 - val_accuracy: 0.5365 - val_false_positives: 213.0000\n",
            "Epoch 57/100\n",
            "72/72 [==============================] - 42s 538ms/step - loss: 0.2070 - accuracy: 0.9902 - false_positives: 5.8630 - val_loss: 1.6173 - val_accuracy: 0.5590 - val_false_positives: 198.0000\n",
            "Epoch 58/100\n",
            "72/72 [==============================] - 43s 555ms/step - loss: 0.1972 - accuracy: 0.9911 - false_positives: 6.1233 - val_loss: 1.5936 - val_accuracy: 0.5365 - val_false_positives: 194.0000\n",
            "Epoch 59/100\n",
            "72/72 [==============================] - 44s 554ms/step - loss: 0.1995 - accuracy: 0.9899 - false_positives: 7.7123 - val_loss: 1.5772 - val_accuracy: 0.5434 - val_false_positives: 193.0000\n",
            "Epoch 60/100\n",
            "72/72 [==============================] - 42s 530ms/step - loss: 0.1940 - accuracy: 0.9929 - false_positives: 8.2192 - val_loss: 1.7468 - val_accuracy: 0.5295 - val_false_positives: 215.0000\n",
            "Epoch 61/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.1875 - accuracy: 0.9943 - false_positives: 4.9315 - val_loss: 1.6415 - val_accuracy: 0.5625 - val_false_positives: 191.0000\n",
            "Epoch 62/100\n",
            "72/72 [==============================] - 42s 533ms/step - loss: 0.1798 - accuracy: 0.9971 - false_positives: 1.7260 - val_loss: 1.6069 - val_accuracy: 0.5347 - val_false_positives: 207.0000\n",
            "Epoch 63/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.1749 - accuracy: 0.9986 - false_positives: 1.1370 - val_loss: 1.6269 - val_accuracy: 0.5312 - val_false_positives: 211.0000\n",
            "Epoch 64/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 0.1753 - accuracy: 0.9962 - false_positives: 3.9178 - val_loss: 1.5377 - val_accuracy: 0.5660 - val_false_positives: 195.0000\n",
            "Epoch 65/100\n",
            "72/72 [==============================] - 42s 530ms/step - loss: 0.1769 - accuracy: 0.9961 - false_positives: 2.3973 - val_loss: 1.5633 - val_accuracy: 0.5503 - val_false_positives: 202.0000\n",
            "Epoch 66/100\n",
            "72/72 [==============================] - 42s 530ms/step - loss: 0.1739 - accuracy: 0.9966 - false_positives: 4.7123 - val_loss: 1.6512 - val_accuracy: 0.5573 - val_false_positives: 202.0000\n",
            "Epoch 67/100\n",
            "72/72 [==============================] - 42s 533ms/step - loss: 0.1835 - accuracy: 0.9927 - false_positives: 6.6301 - val_loss: 1.6392 - val_accuracy: 0.5694 - val_false_positives: 192.0000\n",
            "Epoch 68/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.1787 - accuracy: 0.9962 - false_positives: 4.5890 - val_loss: 1.5054 - val_accuracy: 0.5573 - val_false_positives: 195.0000\n",
            "Epoch 69/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 0.1687 - accuracy: 0.9965 - false_positives: 2.7260 - val_loss: 1.6508 - val_accuracy: 0.5278 - val_false_positives: 211.0000\n",
            "Epoch 70/100\n",
            "72/72 [==============================] - 42s 533ms/step - loss: 0.1725 - accuracy: 0.9947 - false_positives: 5.3425 - val_loss: 1.6408 - val_accuracy: 0.5417 - val_false_positives: 208.0000\n",
            "Epoch 71/100\n",
            "72/72 [==============================] - 42s 530ms/step - loss: 0.1746 - accuracy: 0.9974 - false_positives: 2.1096 - val_loss: 1.6915 - val_accuracy: 0.5365 - val_false_positives: 220.0000\n",
            "Epoch 72/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.1692 - accuracy: 0.9995 - false_positives: 0.9178 - val_loss: 1.6619 - val_accuracy: 0.5382 - val_false_positives: 206.0000\n",
            "Epoch 73/100\n",
            "72/72 [==============================] - 43s 554ms/step - loss: 0.1692 - accuracy: 0.9973 - false_positives: 1.7123 - val_loss: 1.6529 - val_accuracy: 0.5538 - val_false_positives: 213.0000\n",
            "Epoch 74/100\n",
            "72/72 [==============================] - 42s 537ms/step - loss: 0.1692 - accuracy: 0.9982 - false_positives: 1.8630 - val_loss: 1.7068 - val_accuracy: 0.5312 - val_false_positives: 217.0000\n",
            "Epoch 75/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.1680 - accuracy: 0.9962 - false_positives: 3.9589 - val_loss: 1.6471 - val_accuracy: 0.5469 - val_false_positives: 213.0000\n",
            "Epoch 76/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.1711 - accuracy: 0.9958 - false_positives: 5.4795 - val_loss: 1.6663 - val_accuracy: 0.5573 - val_false_positives: 209.0000\n",
            "Epoch 77/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.1616 - accuracy: 0.9994 - false_positives: 0.0000e+00 - val_loss: 1.6595 - val_accuracy: 0.5590 - val_false_positives: 197.0000\n",
            "Epoch 78/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 0.1593 - accuracy: 0.9985 - false_positives: 0.1370 - val_loss: 1.7607 - val_accuracy: 0.5417 - val_false_positives: 202.0000\n",
            "Epoch 79/100\n",
            "72/72 [==============================] - 42s 533ms/step - loss: 0.1725 - accuracy: 0.9927 - false_positives: 5.6986 - val_loss: 1.7236 - val_accuracy: 0.5660 - val_false_positives: 201.0000\n",
            "Epoch 80/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.1703 - accuracy: 0.9966 - false_positives: 3.3014 - val_loss: 1.7974 - val_accuracy: 0.5243 - val_false_positives: 226.0000\n",
            "Epoch 81/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 0.1830 - accuracy: 0.9875 - false_positives: 7.0274 - val_loss: 1.7006 - val_accuracy: 0.5556 - val_false_positives: 204.0000\n",
            "Epoch 82/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.1653 - accuracy: 0.9968 - false_positives: 2.1233 - val_loss: 1.6095 - val_accuracy: 0.5590 - val_false_positives: 209.0000\n",
            "Epoch 83/100\n",
            "72/72 [==============================] - 42s 539ms/step - loss: 0.1614 - accuracy: 0.9985 - false_positives: 1.8767 - val_loss: 1.7325 - val_accuracy: 0.5365 - val_false_positives: 213.0000\n",
            "Epoch 84/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.1590 - accuracy: 0.9977 - false_positives: 1.1096 - val_loss: 1.9450 - val_accuracy: 0.5122 - val_false_positives: 240.0000\n",
            "Epoch 85/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.1612 - accuracy: 0.9990 - false_positives: 1.3014 - val_loss: 1.9219 - val_accuracy: 0.5486 - val_false_positives: 227.0000\n",
            "Epoch 86/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.1556 - accuracy: 0.9985 - false_positives: 2.1233 - val_loss: 1.6788 - val_accuracy: 0.5417 - val_false_positives: 212.0000\n",
            "Epoch 87/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 0.1528 - accuracy: 1.0000 - false_positives: 0.0000e+00 - val_loss: 1.6509 - val_accuracy: 0.5799 - val_false_positives: 199.0000\n",
            "Epoch 88/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 0.1503 - accuracy: 0.9995 - false_positives: 0.7397 - val_loss: 1.6725 - val_accuracy: 0.5920 - val_false_positives: 193.0000\n",
            "Epoch 89/100\n",
            "72/72 [==============================] - 42s 537ms/step - loss: 0.1680 - accuracy: 0.9940 - false_positives: 4.7534 - val_loss: 1.8853 - val_accuracy: 0.5208 - val_false_positives: 236.0000\n",
            "Epoch 90/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.1572 - accuracy: 0.9996 - false_positives: 0.6164 - val_loss: 1.7293 - val_accuracy: 0.5469 - val_false_positives: 209.0000\n",
            "Epoch 91/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.1557 - accuracy: 0.9999 - false_positives: 0.2603 - val_loss: 1.8033 - val_accuracy: 0.5451 - val_false_positives: 225.0000\n",
            "Epoch 92/100\n",
            "72/72 [==============================] - 42s 537ms/step - loss: 0.1526 - accuracy: 0.9994 - false_positives: 0.3836 - val_loss: 1.7043 - val_accuracy: 0.5590 - val_false_positives: 211.0000\n",
            "Epoch 93/100\n",
            "72/72 [==============================] - 42s 536ms/step - loss: 0.1507 - accuracy: 0.9998 - false_positives: 0.3973 - val_loss: 1.6883 - val_accuracy: 0.5712 - val_false_positives: 200.0000\n",
            "Epoch 94/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.1496 - accuracy: 0.9986 - false_positives: 2.3014 - val_loss: 1.7687 - val_accuracy: 0.5365 - val_false_positives: 228.0000\n",
            "Epoch 95/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.1591 - accuracy: 0.9978 - false_positives: 3.1096 - val_loss: 1.7387 - val_accuracy: 0.5747 - val_false_positives: 205.0000\n",
            "Epoch 96/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.1592 - accuracy: 0.9978 - false_positives: 1.8630 - val_loss: 1.7731 - val_accuracy: 0.5712 - val_false_positives: 197.0000\n",
            "Epoch 97/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.1535 - accuracy: 0.9978 - false_positives: 2.5753 - val_loss: 1.6701 - val_accuracy: 0.5851 - val_false_positives: 194.0000\n",
            "Epoch 98/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.1487 - accuracy: 0.9993 - false_positives: 1.0548 - val_loss: 1.7045 - val_accuracy: 0.5590 - val_false_positives: 206.0000\n",
            "Epoch 99/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.1501 - accuracy: 0.9978 - false_positives: 1.0000 - val_loss: 1.7234 - val_accuracy: 0.5660 - val_false_positives: 213.0000\n",
            "Epoch 100/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.1586 - accuracy: 0.9954 - false_positives: 3.7123 - val_loss: 1.8689 - val_accuracy: 0.5503 - val_false_positives: 223.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlh8lxRevAje"
      },
      "source": [
        "# Training with transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3MykDRqvE-7"
      },
      "source": [
        "# def transferLearning():  \n",
        "#   #Set pretrained Layers\n",
        "#   #for layer in model.layers[:150]:\n",
        "#   #    layer.trainable=False\n",
        "#   #for layer in model.layers[150:]:\n",
        "#   #    layer.trainable=True\n",
        "\n",
        "#   #opt = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
        "\n",
        "#   opt  = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "#   for j in range(3,4):\n",
        "#     foldNo = 'fold' + str(j + 1)\n",
        "#     test_set  = testPreprocess(foldNo)\n",
        "#     train_set = trainPreprocess(foldNo)\n",
        "#     print(\"\")\n",
        "#     print(foldNo)\n",
        "    \n",
        "#     epochNo = 100     \n",
        "#     base_model = tf.keras.applications.ResNet101(\n",
        "#     include_top=False, weights='imagenet', classes=3)\n",
        "#     x=base_model.output\n",
        "#     x=GlobalAveragePooling2D()(x)\n",
        "#     preds=Dense(3,activation='softmax')(x) #final layer with softmax activation\n",
        "#     model=Model(inputs=base_model.input,outputs=preds)\n",
        "\n",
        "\n",
        "#     print(\"Epoch: \" + str(epochNo) + \"\\n\\n\")\n",
        "#     model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy', keras.metrics.Precision(), keras.metrics.Recall(), keras.metrics.TruePositives(), keras.metrics.TrueNegatives(), keras.metrics.FalsePositives(), keras.metrics.FalseNegatives()])\n",
        "#     model.fit(x = train_set, validation_data = test_set, epochs = epochNo)\n",
        "#     print(\"Egitim basariyla tamamlandi.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr6YdeGpv8La"
      },
      "source": [
        "def compareLists(l1, l2):\n",
        "  if len(l1) != len(l2):\n",
        "    print('Lengths are not equal!')\n",
        "\n",
        "  check = True  \n",
        "  for i in range(len(l1)):\n",
        "    if l1[i] != l2[i]:\n",
        "      check = False\n",
        "      break\n",
        "  return check\n",
        "\n",
        "def getCategoryValue(x):\n",
        "  yList =[[1. ,  0. ,  0. , 0. ,  0. ,  0. ,  0. , 0.],\n",
        "          [0. ,  1. ,  0. , 0. ,  0. ,  0. ,  0. , 0.],\n",
        "          [0. ,  0. ,  1. , 0. ,  0. ,  0. ,  0. , 0.],\n",
        "          [0. ,  0. ,  0. , 1. ,  0. ,  0. ,  0. , 0.],\n",
        "          [0. ,  0. ,  0. , 0. ,  1. ,  0. ,  0. , 0.],\n",
        "          [0. ,  0. ,  0. , 0. ,  0. ,  1. ,  0. , 0.],\n",
        "          [0. ,  0. ,  0. , 0. ,  0. ,  0. ,  1. , 0.],\n",
        "          [0. ,  0. ,  0. , 0. ,  0. ,  0. ,  0. , 1.]]\n",
        "\n",
        "  for i in range(len(yList)):\n",
        "    if compareLists(x, yList[i]):\n",
        "      return (i + 1)\n",
        "\n",
        "  print(\"Bir değer döndürülemedi, hata var!\")\n",
        "\n",
        "\n",
        "def getDatasetForMachineLearning(train_set, test_set, trainOutput = 1, testOutput = 1):\n",
        "  train_X = []\n",
        "  train_Y = []\n",
        "  test_X = []\n",
        "  test_Y = []\n",
        "\n",
        "  setTrainY = []\n",
        "  setTestY = []\n",
        "\n",
        "  y_doubles = []\n",
        "\n",
        "\n",
        "  # for element in list(test_set.as_numpy_iterator()):\n",
        "  #   for className in element[1]:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for element in list(train_set.as_numpy_iterator()):\n",
        "    for className in element[1]:\n",
        "      train_Y.append(getCategoryValue(className))\n",
        "    for features in element[0]:\n",
        "      train_X.append(features)  \n",
        "  for element in list(test_set.as_numpy_iterator()):\n",
        "    for className in element[1]:\n",
        "      test_Y.append(getCategoryValue(className))\n",
        "    for features in element[0]:\n",
        "      test_X.append(features)   \n",
        "\n",
        "\n",
        "\n",
        "  train_Y = np.array(train_Y)\n",
        "  test_Y = np.array(test_Y)\n",
        "  train_X = np.array(train_X)\n",
        "  test_X = np.array(test_X)\n",
        "\n",
        "  return train_X, train_Y, test_X, test_Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOId3OzNwAkn"
      },
      "source": [
        "def classifyWithMachineLearning(train_set, test_set, cnn_path):\n",
        "    from keras.models import Model\n",
        "    from keras.models import load_model\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    from sklearn.neural_network import MLPClassifier\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "    from sklearn.svm import SVC\n",
        "    from sklearn.naive_bayes import GaussianNB\n",
        "    from sklearn.ensemble import GradientBoostingClassifier\n",
        "    from sklearn.ensemble import AdaBoostClassifier\n",
        "    from sklearn.svm import LinearSVC\n",
        "    import pickle\n",
        "    import cv2\n",
        "  \n",
        "\n",
        "    train_X, train_Y, test_X, test_Y = getDatasetForMachineLearning(train_set, test_set)\n",
        "\n",
        "\n",
        "\n",
        "    random_state = 100\n",
        "\n",
        "    cnn = load_model(cnn_path)\n",
        "    outputLayer = cnn.layers[-5] # Dense layer 512.\n",
        "    print(outputLayer.output.name)\n",
        "\n",
        "    \n",
        "\n",
        "    intermediate_layer_model = Model(inputs=cnn.input,\n",
        "                                    outputs=outputLayer.output)\n",
        "    \n",
        "    print(\"\\nTrain Set:\")\n",
        "    train_output = intermediate_layer_model.predict(train_X)\n",
        "    #print(train_output)\n",
        "    print(\"Boyut1: \" + str(len(train_output)))\n",
        "    print(\"Boyut2: \" + str(len(train_output[0])))\n",
        "    train_output = np.array(train_output)\n",
        "\n",
        "\n",
        "\n",
        "    print(\"\\nTest Set:\")\n",
        "    test_output = intermediate_layer_model.predict(test_X)\n",
        "    #print(test_output)\n",
        "    print(\"Boyut1: \" + str(len(test_output)))\n",
        "    print(\"Boyut2: \" + str(len(test_output[0])))\n",
        "    test_output = np.array(test_output)\n",
        "    \n",
        "    models=[MLPClassifier(max_iter=200000, activation='tanh',solver='lbfgs', random_state=random_state),\n",
        "            LogisticRegression(dual=False,multi_class='auto',solver='lbfgs',random_state=random_state),\n",
        "            RandomForestClassifier(n_estimators=100,criterion='entropy'),\n",
        "            LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto'),\n",
        "            KNeighborsClassifier(n_neighbors=10, weights='distance'),\n",
        "            SVC(kernel='poly',degree=2,C=100, gamma='auto'),\n",
        "            GaussianNB(),\n",
        "            GradientBoostingClassifier(),\n",
        "            AdaBoostClassifier(),\n",
        "            LinearSVC(penalty='l1',dual=False,multi_class='crammer_singer',max_iter=1000000),\n",
        "            SVC(kernel='rbf', random_state=0, gamma=.01, C=100000)]\n",
        "\n",
        "\n",
        "\n",
        "    # model = models[4].fit(train_output, train_Y)   \n",
        "    # model.predict(test_output)\n",
        "    # result = model.score(test_output, test_Y)  \n",
        "    # result2 = model.score(train_output, train_Y)      \n",
        "    # print(\"Test Set Accuracy: \" + str(result))\n",
        "    # print(\"Train Set Accuracy: \" + str(result2))\n",
        "\n",
        "    \n",
        "\n",
        "    model_list = []\n",
        "\n",
        "    for i in range(len(models)):\n",
        "        print(\"\\n\\nModel\" + str(i) + \":\" + str(models[i]))\n",
        "        model = models[i].fit(train_output, train_Y)  # Bad input shape: 1, 3, 5, 6, 7, 8, 9, 10 \n",
        "        model_list.append(model)\n",
        "\n",
        "        testResult = model.score(test_output, test_Y)  \n",
        "        trainResult = model.score(train_output, train_Y) \n",
        "        yPredicted = model.predict(test_output)\n",
        "        confMatrix = confusion_matrix(test_Y, yPredicted)\n",
        "\n",
        "        print(confMatrix)\n",
        "        print(\"Test Set Accuracy: \" + str(testResult))\n",
        "        print(\"Train Set Accuracy: \" + str(trainResult))\n",
        "\n",
        "    return model_list\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91hYZk6sxEdk",
        "outputId": "0b916ec9-38fa-4dad-b1eb-077a9c2b411b"
      },
      "source": [
        "train_set, test_set = getDataset(linear_augNormal_path, seed=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2880 files belonging to 8 classes.\n",
            "Using 2304 files for training.\n",
            "Found 2880 files belonging to 8 classes.\n",
            "Using 576 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "parLBCTTwGj5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeb2ecd5-54a4-44c0-a069-cb0d7c32e9d4"
      },
      "source": [
        "#model = trainCustomCNN3(train_set, test_set)\n",
        "# print((list(train_set.as_numpy_iterator())[35][1]))\n",
        "\n",
        "\n",
        "ml_models = classifyWithMachineLearning(train_set, test_set, \n",
        "                            cnn_path=\"/content/drive/MyDrive/colab/final_project/models/seed100/linear_specAugment.h5\")\n",
        "\n",
        "\n",
        "######################### SEEDLER AYNI VERILMELI #####################\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dense_2/BiasAdd:0\n",
            "\n",
            "Train Set:\n",
            "Boyut1: 2304\n",
            "Boyut2: 512\n",
            "\n",
            "Test Set:\n",
            "Boyut1: 576\n",
            "Boyut2: 512\n",
            "\n",
            "\n",
            "Model0:MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
            "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
            "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
            "              learning_rate_init=0.001, max_fun=15000, max_iter=200000,\n",
            "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
            "              power_t=0.5, random_state=100, shuffle=True, solver='lbfgs',\n",
            "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
            "              warm_start=False)\n",
            "[[20  5  5  3  1  1  0  1]\n",
            " [ 6 51  2  9  0  1  0  3]\n",
            " [ 7  0 46  3  0 10  4  8]\n",
            " [13  5  3 37  1  5  3  1]\n",
            " [ 6  0  5  3 46  6  7  9]\n",
            " [ 0  5 18  0  1 64  0  3]\n",
            " [ 3  1  0  1  5  3 62  3]\n",
            " [ 3  2  7  2  1  4  4 48]]\n",
            "Test Set Accuracy: 0.6493055555555556\n",
            "Train Set Accuracy: 1.0\n",
            "\n",
            "\n",
            "Model1:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[24  4  1  5  0  1  0  1]\n",
            " [ 2 56  3  6  0  0  2  3]\n",
            " [ 2  1 55  2  2  6  2  8]\n",
            " [ 7  7  4 39  2  2  5  2]\n",
            " [ 1  1  5  3 56  1  6  9]\n",
            " [ 0  7 10  1  1 69  0  3]\n",
            " [ 0  1  0  3  6  0 66  2]\n",
            " [ 3  0  4  2  6  2  2 52]]\n",
            "Test Set Accuracy: 0.7239583333333334\n",
            "Train Set Accuracy: 1.0\n",
            "\n",
            "\n",
            "Model2:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='entropy', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "[[17  8  4  5  1  0  0  1]\n",
            " [ 0 63  2  3  0  0  1  3]\n",
            " [ 1  2 47  3  4  9  4  8]\n",
            " [ 0  9  7 44  1  3  2  2]\n",
            " [ 0  2  5  4 51  2 10  8]\n",
            " [ 0  5 10  3  4 64  1  4]\n",
            " [ 0  3  0  2  8  1 61  3]\n",
            " [ 1  1  6  2  4  2  4 51]]\n",
            "Test Set Accuracy: 0.6909722222222222\n",
            "Train Set Accuracy: 1.0\n",
            "\n",
            "\n",
            "Model3:LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage='auto',\n",
            "                           solver='eigen', store_covariance=False, tol=0.0001)\n",
            "[[23  3  4  3  0  1  0  2]\n",
            " [ 1 57  2  7  0  0  2  3]\n",
            " [ 3  1 54  3  0  7  2  8]\n",
            " [ 8  8  5 37  1  3  2  4]\n",
            " [ 1  3  5  2 53  3  5 10]\n",
            " [ 0  6  9  2  2 68  1  3]\n",
            " [ 0  1  0  4  3  2 65  3]\n",
            " [ 2  0  2  3  3  1  1 59]]\n",
            "Test Set Accuracy: 0.7222222222222222\n",
            "Train Set Accuracy: 1.0\n",
            "\n",
            "\n",
            "Model4:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
            "                     weights='distance')\n",
            "[[28  4  1  2  0  0  0  1]\n",
            " [ 2 61  2  2  0  0  2  3]\n",
            " [ 4  1 50  0  2  8  2 11]\n",
            " [10 10  0 40  2  1  1  4]\n",
            " [ 3  1  3  2 60  1  2 10]\n",
            " [ 3  7  5  2  5 65  1  3]\n",
            " [ 1  3  0  3  9  1 59  2]\n",
            " [ 3  0  6  1  3  0  1 57]]\n",
            "Test Set Accuracy: 0.7291666666666666\n",
            "Train Set Accuracy: 1.0\n",
            "\n",
            "\n",
            "Model5:SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=2, gamma='auto', kernel='poly',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n",
            "[[26  3  1  5  0  0  0  1]\n",
            " [ 2 55  2  9  0  0  1  3]\n",
            " [ 2  0 55  3  2  7  2  7]\n",
            " [10  6  5 41  0  1  2  3]\n",
            " [ 1  0  5  3 60  0  3 10]\n",
            " [ 0  5 11  1  3 66  1  4]\n",
            " [ 0  1  1  2  5  1 66  2]\n",
            " [ 1  0  5  2  5  2  2 54]]\n",
            "Test Set Accuracy: 0.734375\n",
            "Train Set Accuracy: 1.0\n",
            "\n",
            "\n",
            "Model6:GaussianNB(priors=None, var_smoothing=1e-09)\n",
            "[[24  7  1  4  0  0  0  0]\n",
            " [ 3 63  1  3  0  0  0  2]\n",
            " [ 4  6 36  6  5  9  3  9]\n",
            " [11  9  1 39  2  1  2  3]\n",
            " [ 3  2  5  6 44  0 16  6]\n",
            " [ 2  7  5  4  7 61  1  4]\n",
            " [ 2  1  0  4  6  0 64  1]\n",
            " [ 3  1  2  6  4  0  3 52]]\n",
            "Test Set Accuracy: 0.6649305555555556\n",
            "Train Set Accuracy: 0.9939236111111112\n",
            "\n",
            "\n",
            "Model7:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "                           max_features=None, max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=1, min_samples_split=2,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                           n_iter_no_change=None, presort='deprecated',\n",
            "                           random_state=None, subsample=1.0, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "[[16  5  5  7  1  1  0  1]\n",
            " [ 1 50  2  6  3  3  3  4]\n",
            " [ 1  2 42  5  5  8  3 12]\n",
            " [ 4  9  6 30  2 12  3  2]\n",
            " [ 2  1  9  6 48  0 10  6]\n",
            " [ 0  5 10  5  4 60  2  5]\n",
            " [ 0  3  1  2 11  3 53  5]\n",
            " [ 2  0  7  3  7  5  1 46]]\n",
            "Test Set Accuracy: 0.5989583333333334\n",
            "Train Set Accuracy: 1.0\n",
            "\n",
            "\n",
            "Model8:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
            "                   n_estimators=50, random_state=None)\n",
            "[[11  4  3  9  0  2  2  5]\n",
            " [18 28  3 15  2  3  3  0]\n",
            " [ 6  1 29 10  9 12  4  7]\n",
            " [14  6 11 22  2  4  4  5]\n",
            " [ 2  2  3  9 38 15  4  9]\n",
            " [ 1  4 20  8  4 43  2  9]\n",
            " [ 2  4  6 18  5  8 29  6]\n",
            " [ 4  3 10  6  6 12  3 27]]\n",
            "Test Set Accuracy: 0.3940972222222222\n",
            "Train Set Accuracy: 0.6961805555555556\n",
            "\n",
            "\n",
            "Model9:LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000000,\n",
            "          multi_class='crammer_singer', penalty='l1', random_state=None,\n",
            "          tol=0.0001, verbose=0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[26  2  1  5  0  1  0  1]\n",
            " [ 2 57  2  6  0  0  2  3]\n",
            " [ 3  0 53  2  4  5  3  8]\n",
            " [ 7  7  4 40  3  1  2  4]\n",
            " [ 1  2  5  2 56  1  6  9]\n",
            " [ 0  7 10  1  1 69  0  3]\n",
            " [ 0  1  1  3  5  0 67  1]\n",
            " [ 3  0  4  2  6  2  3 51]]\n",
            "Test Set Accuracy: 0.7274305555555556\n",
            "Train Set Accuracy: 1.0\n",
            "\n",
            "\n",
            "Model10:SVC(C=100000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=0, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n",
            "[[17  9  3  7  0  0  0  0]\n",
            " [ 0 63  2  3  0  0  2  2]\n",
            " [ 1  3 50  7  1  4  3  9]\n",
            " [ 3 10  4 44  0  1  3  3]\n",
            " [ 1  2  5  5 52  0  9  8]\n",
            " [ 0  8  9  4  5 61  1  3]\n",
            " [ 0  2  0  6  4  0 63  3]\n",
            " [ 1  2  4  5  5  2  5 47]]\n",
            "Test Set Accuracy: 0.6892361111111112\n",
            "Train Set Accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9oLimFzML8x"
      },
      "source": [
        "import pickle\n",
        "\n",
        "ml_models_dict = {\n",
        "        0: \"MLPClassifier\",\n",
        "        1: \"LogisticRegression\",\n",
        "        2: \"RandomForestClassifier\",\n",
        "        3: \"LinearDiscriminantAnalysis\",\n",
        "        4: \"KNeighborsClassifier\",\n",
        "        5: \"SVC_Polynomial_Kernel\",\n",
        "        6: \"GaussianNB\",\n",
        "        7: \"GradientBoostingClassifier\",\n",
        "        8: \"AdaBoostClassifier\",\n",
        "        9: \"LinearSVC\",\n",
        "        10: \"SVC_RBF_Kernel\"\n",
        "    }\n",
        "\n",
        "for i in range(len(ml_models)):\n",
        "    pickle.dump(ml_models[i], open(\"./models/ml_models/\" + ml_models_dict[i] + \".sav\", 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_cawO9x2vCO"
      },
      "source": [
        "# CNN Model Stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq0F1hTs83qj",
        "outputId": "3e097533-c16a-4aa5-c7a4-69ffa06bd4d3"
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "_, test_set = getDataset(log_path, seed=50)\n",
        "model = keras.models.load_model(\"/content/drive/MyDrive/colab/final_project/models/seed50/log_original.h5\")\n",
        "\n",
        "# print(test_set)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1440 files belonging to 8 classes.\n",
            "Using 1152 files for training.\n",
            "Found 1440 files belonging to 8 classes.\n",
            "Using 288 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ksIkKCz2uoN",
        "outputId": "6c37b71d-1195-47fb-9c18-2b1dc7181e30"
      },
      "source": [
        "predictions = np.array([])\n",
        "labels =  np.array([])\n",
        "for x, y in test_set:\n",
        "    predictions = np.concatenate([predictions, model.predict_classes(x)])\n",
        "    labels = np.concatenate([labels, np.argmax(y.numpy(), axis=-1)])\n",
        "\n",
        "\n",
        "print(\"Acc:\", metrics.accuracy_score(labels, predictions))\n",
        "\n",
        "\n",
        "confusion_mat = metrics.confusion_matrix(labels, predictions)\n",
        "print(confusion_mat)\n"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Acc: 0.6701388888888888\n",
            "[[ 8  8  0  2  0  0  0  1]\n",
            " [ 3 29  0  4  0  1  0  0]\n",
            " [ 3  0 17  0 10  3  3  1]\n",
            " [ 3  2  5 20  1  2  3  1]\n",
            " [ 0  1  2  0 34  1  2  1]\n",
            " [ 0  1  4  3  1 30  0  4]\n",
            " [ 1  3  1  3  0  0 27  1]\n",
            " [ 1  3  2  0  1  2  1 28]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}