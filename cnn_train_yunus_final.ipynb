{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cnn_train.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RMUVEPs5GBfD",
        "wAik2giqGhcp",
        "7Njs0Z49aLb-"
      ],
      "mount_file_id": "1bKCP2YXLqn4gSnvSbRih0W4i5q987ohD",
      "authorship_tag": "ABX9TyORTpAWn3QwbmK7rpkiYuMs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YunusKaratepe/duygu-tanima/blob/main/cnn_train_yunus_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zTCT376Fy7H"
      },
      "source": [
        "# Import drive and arrange path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O68bTzOjGUn7",
        "outputId": "3406c2f4-0c55-4d74-e2fc-af41cf0e9e07"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUriPVZqEupb",
        "outputId": "c7c40a0d-885f-4f87-8fd4-5f19b0888d05"
      },
      "source": [
        "%cd /content/drive/MyDrive/colab/final_project"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/colab/final_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gCUJJ5gxFWaJ",
        "outputId": "219e029e-85d8-4c45-a8db-03725910d56c"
      },
      "source": [
        "%pwd # displays current path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/colab/final_project'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMUVEPs5GBfD"
      },
      "source": [
        "# Import libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhPrn2oDFjjD"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization\n",
        "from keras.layers import Dropout, Flatten, Conv2D, MaxPooling2D, Activation\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import activations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iIaiCdX6Y0s",
        "outputId": "1d51e760-b379-4d3d-fb90-08353417a4b0"
      },
      "source": [
        "# checking gpu device\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 18246028955128570486, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14509932544\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 12514682585921123519\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAik2giqGhcp"
      },
      "source": [
        "# Get data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL3azXD9GuB2"
      },
      "source": [
        "My data paths:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20AFNAT6GxfV"
      },
      "source": [
        "linear_path = './spec_data/LinearSpectrogram/LinearSpectrogramOriginal/'\n",
        "linear_augNormal_path = './spec_data/LinearSpectrogram/LinearSpectrogram_AugNormal/'\n",
        "linear_augDerivative1_path = './spec_data/LinearSpectrogram/LinearSpectrogram_AugDerivativeOrder1/'\n",
        "linear_augDerivative2_path = './spec_data/LinearSpectrogram/LinearSpectrogram_AugDerivativeOrder2/'\n",
        "\n",
        "log_path = './spec_data/LogSpectrogram/LogSpectrogramOriginal/'\n",
        "log_augNormal_path = './spec_data/LogSpectrogram/LogSpectrogram_AugNormal/'\n",
        "log_augDerivative1_path = './spec_data/LogSpectrogram/LogSpectrogram_AugDerivativeOrder1/' \n",
        "log_augDerivative2_path = './spec_data/LogSpectrogram/LogSpectrogram_AugDerivativeOrder2/'\n",
        "\n",
        "mel128_augNormal = '/spec_data/MelSpectrogram128'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Afi8ix_gGg-g"
      },
      "source": [
        "def getDataset(directory: str, seed: int): \n",
        "\n",
        "  train_set=tf.keras.preprocessing.image_dataset_from_directory(\n",
        "      directory,\n",
        "      labels=\"inferred\",\n",
        "      label_mode=\"categorical\",\n",
        "      subset=\"training\",\n",
        "      class_names=None,\n",
        "      shuffle=True,\n",
        "      seed = seed, #10 50 100 verecegiz \n",
        "      batch_size=32,\n",
        "      image_size=(128, 128),\n",
        "      validation_split = 0.2,\n",
        "      #interpolation=\"lanczos5\"\n",
        "  )\n",
        "\n",
        "  test_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "      directory,\n",
        "      labels=\"inferred\",\n",
        "      label_mode=\"categorical\",\n",
        "      subset=\"validation\",\n",
        "      validation_split = 0.2,\n",
        "      class_names=None,\n",
        "      shuffle=True,\n",
        "      seed = seed, #10 50 100 verecegiz\n",
        "      batch_size=32,\n",
        "      image_size=(128, 128),\n",
        "      #interpolation=\"lanczos5\"\n",
        "  )\n",
        "  #print(test_set)\n",
        "  #for data, labels in test_set:\n",
        "    #print(data.shape)  # (64, 200, 200, 3)\n",
        "  return train_set, test_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Njs0Z49aLb-"
      },
      "source": [
        "# Training of custom CNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vfk-P0RnDecH"
      },
      "source": [
        "0.59 max başarı, 20 epoch'ta acc=1.0 ->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA8kig0WaIIk"
      },
      "source": [
        "# def trainCustomCNN(train_set, test_set):\n",
        "#   X_train  = train_set\n",
        "#   opt  = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "\n",
        "#   model = keras.Sequential() \n",
        "  \n",
        "#   model.add(keras.layers.Conv2D(128, input_shape=(128,72,3), kernel_size=80, strides=4, padding='same', kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(l=0.0001)))\n",
        "#   model.add(keras.layers.BatchNormalization())\n",
        "#   model.add(keras.layers.Activation('relu'))\n",
        "#   model.add(keras.layers.MaxPooling2D(pool_size=4, strides=None, padding='same'))\n",
        "\n",
        "#   model.add(keras.layers.Conv2D(128, kernel_size=3, strides=1, padding='same', kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(l=0.0001)))\n",
        "#   model.add(keras.layers.BatchNormalization())\n",
        "#   model.add(keras.layers.Activation('relu'))\n",
        "#   model.add(keras.layers.MaxPooling2D(pool_size=2, strides=None, padding='same'))\n",
        "\n",
        "#   model.add(keras.layers.Conv2D(256, kernel_size=3, strides=1, padding='same', kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(l=0.0001)))\n",
        "#   model.add(keras.layers.BatchNormalization())\n",
        "#   model.add(keras.layers.Activation('relu'))\n",
        "#   model.add(keras.layers.MaxPooling2D(pool_size=2, strides=None, padding='same'))\n",
        "\n",
        "#   model.add(keras.layers.Conv2D(512, kernel_size=3, strides=1, padding='same', kernel_initializer='glorot_uniform', kernel_regularizer=keras.regularizers.l2(l=0.0001)))\n",
        "#   model.add(keras.layers.BatchNormalization())\n",
        "#   model.add(keras.layers.Activation('relu'))\n",
        "#   model.add(keras.layers.MaxPooling2D(pool_size=2, strides=None, padding='same'))\n",
        "\n",
        "\n",
        "#   model.add(keras.layers.Lambda(lambda x : keras.backend.mean(x, axis=1)))\n",
        "#   model.add(keras.layers.Lambda(lambda x : keras.backend.mean(x, axis=1)))\n",
        "#   model.add(keras.layers.Dense(8, activation='softmax'))\n",
        "\n",
        "#   model.compile(optimizer = opt, loss='categorical_crossentropy',metrics = ['accuracy', keras.metrics.TruePositives(), keras.metrics.TrueNegatives(), keras.metrics.FalsePositives(), keras.metrics.FalseNegatives()]) \n",
        "#   model.summary()  \n",
        "#   model.fit(x = X_train, validation_data = test_set, epochs = 50)\n",
        "#   model.save('./models/my_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF39C_4RMl8u"
      },
      "source": [
        "Ahmetlerin modeli, başarı düşük ->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RFbv5fRzoVb"
      },
      "source": [
        "# def trainCustomCNN(train_set, test_set, numof_classes):\n",
        "\n",
        "#     model = keras.Sequential()\n",
        "#     # LFLB1\n",
        "#     model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', data_format='channels_last',input_shape=(128,128,3)))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(Activation('elu'))\n",
        "#     model.add(MaxPooling2D(pool_size=(4,4), strides=(2,2)))\n",
        "#     model.add(Dropout(0.5))\n",
        "\n",
        "#     model.add(Conv2D(filters=128,kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(Activation('elu'))\n",
        "#     model.add(MaxPooling2D(pool_size=(2,2), strides=(4,4)))\n",
        "#     model.add(Dropout(0.25))\n",
        "\n",
        "#     model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(Activation('elu'))\n",
        "#     model.add(MaxPooling2D(pool_size=(2,2), strides=(4,4)))\n",
        "#     model.add(Dropout(0.25))\n",
        "\n",
        "#     model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(Activation('elu'))\n",
        "#     model.add(MaxPooling2D(pool_size=(2,2), strides=(4,4)))\n",
        "#     model.add(Dropout(0.25))\n",
        "\n",
        "#     model.add(Flatten())\n",
        "#     # FC\n",
        "#     model.add(Dense(8, activation='softmax'))\n",
        "\n",
        "#     # Model compilation\n",
        "#     opt = optimizers.Adam(lr=0.001, beta_1=0.9,  beta_2=0.999, amsgrad=False)\n",
        "#     model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy', keras.metrics.FalsePositives()])\n",
        "#     model.summary()\n",
        "#     model.fit(x = train_set, validation_data = test_set, epochs = 100)\n",
        "#     model.save('./models/ahmet_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcrC_D3-MhHW"
      },
      "source": [
        "En başarılı model ->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_D0wE1lDaw3"
      },
      "source": [
        "def trainCustomCNN(train_set, test_set, numof_classes, specType, seed):\n",
        "    X_train  = train_set\n",
        "    opt  = tf.keras.optimizers.Adam(learning_rate=0.00005)\n",
        "\n",
        "    #input_shape=(128, 128),\n",
        "    model = keras.Sequential() \n",
        "\n",
        "    model.add(keras.layers.Conv2D(64, input_shape=(128, 128, 3), kernel_size=(3,3), \n",
        "                                  strides=(1,1), padding='same', \n",
        "                                  kernel_regularizer=keras.regularizers.l2(l=0.0005)))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Activation('relu'))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=4, strides=None, padding='same'))\n",
        "\n",
        "\n",
        "    model.add(keras.layers.Conv2D(64, kernel_size=(3,3), strides=1, padding='same', \n",
        "                                  kernel_regularizer=keras.regularizers.l2(l=0.0005)))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Activation('relu'))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=2, strides=None, padding='same'))\n",
        "\n",
        "\n",
        "    model.add(keras.layers.Conv2D(128, kernel_size=(3,3), strides=1, padding='same', \n",
        "                                  kernel_regularizer=keras.regularizers.l2(l=0.0005)))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Activation('relu'))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=2, strides=None, padding='same'))\n",
        "\n",
        "\n",
        "    model.add(keras.layers.Conv2D(128, kernel_size=(3,3), strides=1, padding='same', \n",
        "                                  kernel_regularizer=keras.regularizers.l2(l=0.0005)))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Activation('relu'))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=2, strides=None, padding='same'))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(keras.layers.Dense(numof_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer = opt, loss='categorical_crossentropy', metrics = ['accuracy', keras.metrics.FalsePositives()]) \n",
        "    model.summary()\n",
        "    model.fit(x = X_train, validation_data = test_set, epochs = 100)\n",
        "    model.save('./models/seed' + str(seed) + '/'  + specType + '.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRKlVGV_Fucg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18ebcb52-dca3-4a9a-db4c-ebe108f9d24d"
      },
      "source": [
        "train_set, test_set = getDataset(linear_augDerivative2_path, seed=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2880 files belonging to 8 classes.\n",
            "Using 2304 files for training.\n",
            "Found 2880 files belonging to 8 classes.\n",
            "Using 576 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWJrZdKNa5dq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecdfca64-c121-4d61-f731-e1669de6eeeb"
      },
      "source": [
        "trainCustomCNN(train_set, test_set, numof_classes=8, specType='mel128_specAugment', seed=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 128, 128, 64)      1792      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 128, 128, 64)      256       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 4104      \n",
            "=================================================================\n",
            "Total params: 1,316,936\n",
            "Trainable params: 1,315,144\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "72/72 [==============================] - 389s 4s/step - loss: 2.9506 - accuracy: 0.1727 - false_positives: 433.9041 - val_loss: 2.6410 - val_accuracy: 0.1632 - val_false_positives: 33.0000\n",
            "Epoch 2/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 2.3617 - accuracy: 0.2629 - false_positives: 379.3699 - val_loss: 2.1565 - val_accuracy: 0.2396 - val_false_positives: 43.0000\n",
            "Epoch 3/100\n",
            "72/72 [==============================] - 42s 530ms/step - loss: 2.1768 - accuracy: 0.3167 - false_positives: 343.3836 - val_loss: 1.9171 - val_accuracy: 0.3403 - val_false_positives: 35.0000\n",
            "Epoch 4/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 2.0850 - accuracy: 0.3414 - false_positives: 342.5205 - val_loss: 1.8731 - val_accuracy: 0.3420 - val_false_positives: 81.0000\n",
            "Epoch 5/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 1.9197 - accuracy: 0.3952 - false_positives: 317.9589 - val_loss: 1.7862 - val_accuracy: 0.3785 - val_false_positives: 80.0000\n",
            "Epoch 6/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 1.8287 - accuracy: 0.4053 - false_positives: 323.6849 - val_loss: 1.8175 - val_accuracy: 0.3646 - val_false_positives: 114.0000\n",
            "Epoch 7/100\n",
            "72/72 [==============================] - 42s 530ms/step - loss: 1.7685 - accuracy: 0.4216 - false_positives: 312.6301 - val_loss: 1.7270 - val_accuracy: 0.4306 - val_false_positives: 95.0000\n",
            "Epoch 8/100\n",
            "72/72 [==============================] - 42s 530ms/step - loss: 1.6845 - accuracy: 0.4671 - false_positives: 288.0274 - val_loss: 1.7099 - val_accuracy: 0.4288 - val_false_positives: 107.0000\n",
            "Epoch 9/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 1.5445 - accuracy: 0.4893 - false_positives: 253.0822 - val_loss: 1.7875 - val_accuracy: 0.3976 - val_false_positives: 135.0000\n",
            "Epoch 10/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 1.4824 - accuracy: 0.5119 - false_positives: 279.1918 - val_loss: 1.6651 - val_accuracy: 0.4688 - val_false_positives: 111.0000\n",
            "Epoch 11/100\n",
            "72/72 [==============================] - 42s 533ms/step - loss: 1.3817 - accuracy: 0.5617 - false_positives: 249.6712 - val_loss: 1.7363 - val_accuracy: 0.4497 - val_false_positives: 123.0000\n",
            "Epoch 12/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 1.3209 - accuracy: 0.5845 - false_positives: 228.3151 - val_loss: 1.6457 - val_accuracy: 0.4670 - val_false_positives: 131.0000\n",
            "Epoch 13/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 1.2424 - accuracy: 0.6082 - false_positives: 208.9452 - val_loss: 1.6815 - val_accuracy: 0.4653 - val_false_positives: 127.0000\n",
            "Epoch 14/100\n",
            "72/72 [==============================] - 43s 548ms/step - loss: 1.1820 - accuracy: 0.6316 - false_positives: 208.0548 - val_loss: 1.6052 - val_accuracy: 0.4549 - val_false_positives: 140.0000\n",
            "Epoch 15/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 1.0938 - accuracy: 0.6529 - false_positives: 200.5205 - val_loss: 1.5664 - val_accuracy: 0.4705 - val_false_positives: 127.0000\n",
            "Epoch 16/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 1.0870 - accuracy: 0.6551 - false_positives: 194.6438 - val_loss: 1.6664 - val_accuracy: 0.4497 - val_false_positives: 145.0000\n",
            "Epoch 17/100\n",
            "72/72 [==============================] - 42s 536ms/step - loss: 0.9854 - accuracy: 0.6956 - false_positives: 165.8904 - val_loss: 1.5793 - val_accuracy: 0.4809 - val_false_positives: 138.0000\n",
            "Epoch 18/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.9956 - accuracy: 0.7100 - false_positives: 168.3151 - val_loss: 1.5697 - val_accuracy: 0.4931 - val_false_positives: 139.0000\n",
            "Epoch 19/100\n",
            "72/72 [==============================] - 42s 533ms/step - loss: 0.9149 - accuracy: 0.7292 - false_positives: 162.2329 - val_loss: 1.5507 - val_accuracy: 0.4983 - val_false_positives: 145.0000\n",
            "Epoch 20/100\n",
            "72/72 [==============================] - 42s 536ms/step - loss: 0.8882 - accuracy: 0.7543 - false_positives: 143.6164 - val_loss: 1.5725 - val_accuracy: 0.5035 - val_false_positives: 155.0000\n",
            "Epoch 21/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.8165 - accuracy: 0.7679 - false_positives: 128.7123 - val_loss: 1.5563 - val_accuracy: 0.4948 - val_false_positives: 165.0000\n",
            "Epoch 22/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.7584 - accuracy: 0.8041 - false_positives: 120.8356 - val_loss: 1.6033 - val_accuracy: 0.4844 - val_false_positives: 180.0000\n",
            "Epoch 23/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.7136 - accuracy: 0.8148 - false_positives: 118.4932 - val_loss: 1.5227 - val_accuracy: 0.5139 - val_false_positives: 162.0000\n",
            "Epoch 24/100\n",
            "72/72 [==============================] - 42s 538ms/step - loss: 0.6581 - accuracy: 0.8398 - false_positives: 105.7123 - val_loss: 1.5669 - val_accuracy: 0.5278 - val_false_positives: 154.0000\n",
            "Epoch 25/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.6464 - accuracy: 0.8342 - false_positives: 94.3014 - val_loss: 1.5117 - val_accuracy: 0.4965 - val_false_positives: 168.0000\n",
            "Epoch 26/100\n",
            "72/72 [==============================] - 42s 539ms/step - loss: 0.5905 - accuracy: 0.8618 - false_positives: 79.6986 - val_loss: 1.5506 - val_accuracy: 0.5052 - val_false_positives: 163.0000\n",
            "Epoch 27/100\n",
            "72/72 [==============================] - 43s 550ms/step - loss: 0.5468 - accuracy: 0.8811 - false_positives: 70.3014 - val_loss: 1.5506 - val_accuracy: 0.5104 - val_false_positives: 169.0000\n",
            "Epoch 28/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.5345 - accuracy: 0.8779 - false_positives: 79.0000 - val_loss: 1.5204 - val_accuracy: 0.5017 - val_false_positives: 178.0000\n",
            "Epoch 29/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.5110 - accuracy: 0.8986 - false_positives: 69.6986 - val_loss: 1.4871 - val_accuracy: 0.5382 - val_false_positives: 165.0000\n",
            "Epoch 30/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.5121 - accuracy: 0.8856 - false_positives: 71.3699 - val_loss: 1.5572 - val_accuracy: 0.5243 - val_false_positives: 160.0000\n",
            "Epoch 31/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.4756 - accuracy: 0.9028 - false_positives: 50.5342 - val_loss: 1.5229 - val_accuracy: 0.5365 - val_false_positives: 166.0000\n",
            "Epoch 32/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 0.4112 - accuracy: 0.9325 - false_positives: 43.2603 - val_loss: 1.5749 - val_accuracy: 0.5122 - val_false_positives: 179.0000\n",
            "Epoch 33/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.4086 - accuracy: 0.9359 - false_positives: 47.2192 - val_loss: 1.4527 - val_accuracy: 0.5608 - val_false_positives: 150.0000\n",
            "Epoch 34/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.4049 - accuracy: 0.9245 - false_positives: 45.7260 - val_loss: 1.5312 - val_accuracy: 0.5208 - val_false_positives: 183.0000\n",
            "Epoch 35/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.3713 - accuracy: 0.9431 - false_positives: 31.6027 - val_loss: 1.6377 - val_accuracy: 0.5156 - val_false_positives: 172.0000\n",
            "Epoch 36/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.3567 - accuracy: 0.9576 - false_positives: 28.0959 - val_loss: 1.5890 - val_accuracy: 0.5365 - val_false_positives: 181.0000\n",
            "Epoch 37/100\n",
            "72/72 [==============================] - 41s 528ms/step - loss: 0.3171 - accuracy: 0.9675 - false_positives: 20.5342 - val_loss: 1.4690 - val_accuracy: 0.5434 - val_false_positives: 175.0000\n",
            "Epoch 38/100\n",
            "72/72 [==============================] - 42s 530ms/step - loss: 0.3277 - accuracy: 0.9594 - false_positives: 29.1781 - val_loss: 1.5074 - val_accuracy: 0.5538 - val_false_positives: 179.0000\n",
            "Epoch 39/100\n",
            "72/72 [==============================] - 42s 530ms/step - loss: 0.3280 - accuracy: 0.9570 - false_positives: 32.5068 - val_loss: 1.5343 - val_accuracy: 0.5451 - val_false_positives: 183.0000\n",
            "Epoch 40/100\n",
            "72/72 [==============================] - 42s 533ms/step - loss: 0.3133 - accuracy: 0.9646 - false_positives: 23.8767 - val_loss: 1.4809 - val_accuracy: 0.5573 - val_false_positives: 177.0000\n",
            "Epoch 41/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.2821 - accuracy: 0.9754 - false_positives: 16.9863 - val_loss: 1.5418 - val_accuracy: 0.5399 - val_false_positives: 181.0000\n",
            "Epoch 42/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 0.2778 - accuracy: 0.9781 - false_positives: 18.6712 - val_loss: 1.5028 - val_accuracy: 0.5434 - val_false_positives: 176.0000\n",
            "Epoch 43/100\n",
            "72/72 [==============================] - 41s 529ms/step - loss: 0.2795 - accuracy: 0.9704 - false_positives: 21.0411 - val_loss: 1.5029 - val_accuracy: 0.5503 - val_false_positives: 173.0000\n",
            "Epoch 44/100\n",
            "72/72 [==============================] - 42s 529ms/step - loss: 0.2603 - accuracy: 0.9831 - false_positives: 13.2466 - val_loss: 1.5779 - val_accuracy: 0.5191 - val_false_positives: 201.0000\n",
            "Epoch 45/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 0.2538 - accuracy: 0.9796 - false_positives: 13.9315 - val_loss: 1.5891 - val_accuracy: 0.5347 - val_false_positives: 201.0000\n",
            "Epoch 46/100\n",
            "72/72 [==============================] - 41s 529ms/step - loss: 0.2413 - accuracy: 0.9878 - false_positives: 9.0685 - val_loss: 1.6274 - val_accuracy: 0.5122 - val_false_positives: 203.0000\n",
            "Epoch 47/100\n",
            "72/72 [==============================] - 42s 530ms/step - loss: 0.2517 - accuracy: 0.9778 - false_positives: 17.2603 - val_loss: 1.5930 - val_accuracy: 0.5382 - val_false_positives: 199.0000\n",
            "Epoch 48/100\n",
            "72/72 [==============================] - 41s 529ms/step - loss: 0.2371 - accuracy: 0.9835 - false_positives: 17.1918 - val_loss: 1.5702 - val_accuracy: 0.5243 - val_false_positives: 207.0000\n",
            "Epoch 49/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 0.2205 - accuracy: 0.9904 - false_positives: 7.3425 - val_loss: 1.5807 - val_accuracy: 0.5486 - val_false_positives: 192.0000\n",
            "Epoch 50/100\n",
            "72/72 [==============================] - 41s 529ms/step - loss: 0.2193 - accuracy: 0.9897 - false_positives: 7.1096 - val_loss: 1.6094 - val_accuracy: 0.5347 - val_false_positives: 194.0000\n",
            "Epoch 51/100\n",
            "72/72 [==============================] - 41s 528ms/step - loss: 0.2437 - accuracy: 0.9805 - false_positives: 9.3151 - val_loss: 1.6393 - val_accuracy: 0.5330 - val_false_positives: 195.0000\n",
            "Epoch 52/100\n",
            "72/72 [==============================] - 43s 554ms/step - loss: 0.2190 - accuracy: 0.9863 - false_positives: 7.1096 - val_loss: 1.5707 - val_accuracy: 0.5538 - val_false_positives: 188.0000\n",
            "Epoch 53/100\n",
            "72/72 [==============================] - 42s 538ms/step - loss: 0.2053 - accuracy: 0.9894 - false_positives: 8.0822 - val_loss: 1.5381 - val_accuracy: 0.5486 - val_false_positives: 186.0000\n",
            "Epoch 54/100\n",
            "72/72 [==============================] - 41s 528ms/step - loss: 0.2058 - accuracy: 0.9923 - false_positives: 7.2603 - val_loss: 1.6036 - val_accuracy: 0.5469 - val_false_positives: 188.0000\n",
            "Epoch 55/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.2033 - accuracy: 0.9933 - false_positives: 2.9863 - val_loss: 1.6440 - val_accuracy: 0.5260 - val_false_positives: 203.0000\n",
            "Epoch 56/100\n",
            "72/72 [==============================] - 42s 530ms/step - loss: 0.1948 - accuracy: 0.9934 - false_positives: 6.7671 - val_loss: 1.6452 - val_accuracy: 0.5365 - val_false_positives: 213.0000\n",
            "Epoch 57/100\n",
            "72/72 [==============================] - 42s 538ms/step - loss: 0.2070 - accuracy: 0.9902 - false_positives: 5.8630 - val_loss: 1.6173 - val_accuracy: 0.5590 - val_false_positives: 198.0000\n",
            "Epoch 58/100\n",
            "72/72 [==============================] - 43s 555ms/step - loss: 0.1972 - accuracy: 0.9911 - false_positives: 6.1233 - val_loss: 1.5936 - val_accuracy: 0.5365 - val_false_positives: 194.0000\n",
            "Epoch 59/100\n",
            "72/72 [==============================] - 44s 554ms/step - loss: 0.1995 - accuracy: 0.9899 - false_positives: 7.7123 - val_loss: 1.5772 - val_accuracy: 0.5434 - val_false_positives: 193.0000\n",
            "Epoch 60/100\n",
            "72/72 [==============================] - 42s 530ms/step - loss: 0.1940 - accuracy: 0.9929 - false_positives: 8.2192 - val_loss: 1.7468 - val_accuracy: 0.5295 - val_false_positives: 215.0000\n",
            "Epoch 61/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.1875 - accuracy: 0.9943 - false_positives: 4.9315 - val_loss: 1.6415 - val_accuracy: 0.5625 - val_false_positives: 191.0000\n",
            "Epoch 62/100\n",
            "72/72 [==============================] - 42s 533ms/step - loss: 0.1798 - accuracy: 0.9971 - false_positives: 1.7260 - val_loss: 1.6069 - val_accuracy: 0.5347 - val_false_positives: 207.0000\n",
            "Epoch 63/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.1749 - accuracy: 0.9986 - false_positives: 1.1370 - val_loss: 1.6269 - val_accuracy: 0.5312 - val_false_positives: 211.0000\n",
            "Epoch 64/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 0.1753 - accuracy: 0.9962 - false_positives: 3.9178 - val_loss: 1.5377 - val_accuracy: 0.5660 - val_false_positives: 195.0000\n",
            "Epoch 65/100\n",
            "72/72 [==============================] - 42s 530ms/step - loss: 0.1769 - accuracy: 0.9961 - false_positives: 2.3973 - val_loss: 1.5633 - val_accuracy: 0.5503 - val_false_positives: 202.0000\n",
            "Epoch 66/100\n",
            "72/72 [==============================] - 42s 530ms/step - loss: 0.1739 - accuracy: 0.9966 - false_positives: 4.7123 - val_loss: 1.6512 - val_accuracy: 0.5573 - val_false_positives: 202.0000\n",
            "Epoch 67/100\n",
            "72/72 [==============================] - 42s 533ms/step - loss: 0.1835 - accuracy: 0.9927 - false_positives: 6.6301 - val_loss: 1.6392 - val_accuracy: 0.5694 - val_false_positives: 192.0000\n",
            "Epoch 68/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.1787 - accuracy: 0.9962 - false_positives: 4.5890 - val_loss: 1.5054 - val_accuracy: 0.5573 - val_false_positives: 195.0000\n",
            "Epoch 69/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 0.1687 - accuracy: 0.9965 - false_positives: 2.7260 - val_loss: 1.6508 - val_accuracy: 0.5278 - val_false_positives: 211.0000\n",
            "Epoch 70/100\n",
            "72/72 [==============================] - 42s 533ms/step - loss: 0.1725 - accuracy: 0.9947 - false_positives: 5.3425 - val_loss: 1.6408 - val_accuracy: 0.5417 - val_false_positives: 208.0000\n",
            "Epoch 71/100\n",
            "72/72 [==============================] - 42s 530ms/step - loss: 0.1746 - accuracy: 0.9974 - false_positives: 2.1096 - val_loss: 1.6915 - val_accuracy: 0.5365 - val_false_positives: 220.0000\n",
            "Epoch 72/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.1692 - accuracy: 0.9995 - false_positives: 0.9178 - val_loss: 1.6619 - val_accuracy: 0.5382 - val_false_positives: 206.0000\n",
            "Epoch 73/100\n",
            "72/72 [==============================] - 43s 554ms/step - loss: 0.1692 - accuracy: 0.9973 - false_positives: 1.7123 - val_loss: 1.6529 - val_accuracy: 0.5538 - val_false_positives: 213.0000\n",
            "Epoch 74/100\n",
            "72/72 [==============================] - 42s 537ms/step - loss: 0.1692 - accuracy: 0.9982 - false_positives: 1.8630 - val_loss: 1.7068 - val_accuracy: 0.5312 - val_false_positives: 217.0000\n",
            "Epoch 75/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.1680 - accuracy: 0.9962 - false_positives: 3.9589 - val_loss: 1.6471 - val_accuracy: 0.5469 - val_false_positives: 213.0000\n",
            "Epoch 76/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.1711 - accuracy: 0.9958 - false_positives: 5.4795 - val_loss: 1.6663 - val_accuracy: 0.5573 - val_false_positives: 209.0000\n",
            "Epoch 77/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.1616 - accuracy: 0.9994 - false_positives: 0.0000e+00 - val_loss: 1.6595 - val_accuracy: 0.5590 - val_false_positives: 197.0000\n",
            "Epoch 78/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 0.1593 - accuracy: 0.9985 - false_positives: 0.1370 - val_loss: 1.7607 - val_accuracy: 0.5417 - val_false_positives: 202.0000\n",
            "Epoch 79/100\n",
            "72/72 [==============================] - 42s 533ms/step - loss: 0.1725 - accuracy: 0.9927 - false_positives: 5.6986 - val_loss: 1.7236 - val_accuracy: 0.5660 - val_false_positives: 201.0000\n",
            "Epoch 80/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.1703 - accuracy: 0.9966 - false_positives: 3.3014 - val_loss: 1.7974 - val_accuracy: 0.5243 - val_false_positives: 226.0000\n",
            "Epoch 81/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 0.1830 - accuracy: 0.9875 - false_positives: 7.0274 - val_loss: 1.7006 - val_accuracy: 0.5556 - val_false_positives: 204.0000\n",
            "Epoch 82/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.1653 - accuracy: 0.9968 - false_positives: 2.1233 - val_loss: 1.6095 - val_accuracy: 0.5590 - val_false_positives: 209.0000\n",
            "Epoch 83/100\n",
            "72/72 [==============================] - 42s 539ms/step - loss: 0.1614 - accuracy: 0.9985 - false_positives: 1.8767 - val_loss: 1.7325 - val_accuracy: 0.5365 - val_false_positives: 213.0000\n",
            "Epoch 84/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.1590 - accuracy: 0.9977 - false_positives: 1.1096 - val_loss: 1.9450 - val_accuracy: 0.5122 - val_false_positives: 240.0000\n",
            "Epoch 85/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.1612 - accuracy: 0.9990 - false_positives: 1.3014 - val_loss: 1.9219 - val_accuracy: 0.5486 - val_false_positives: 227.0000\n",
            "Epoch 86/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.1556 - accuracy: 0.9985 - false_positives: 2.1233 - val_loss: 1.6788 - val_accuracy: 0.5417 - val_false_positives: 212.0000\n",
            "Epoch 87/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 0.1528 - accuracy: 1.0000 - false_positives: 0.0000e+00 - val_loss: 1.6509 - val_accuracy: 0.5799 - val_false_positives: 199.0000\n",
            "Epoch 88/100\n",
            "72/72 [==============================] - 42s 531ms/step - loss: 0.1503 - accuracy: 0.9995 - false_positives: 0.7397 - val_loss: 1.6725 - val_accuracy: 0.5920 - val_false_positives: 193.0000\n",
            "Epoch 89/100\n",
            "72/72 [==============================] - 42s 537ms/step - loss: 0.1680 - accuracy: 0.9940 - false_positives: 4.7534 - val_loss: 1.8853 - val_accuracy: 0.5208 - val_false_positives: 236.0000\n",
            "Epoch 90/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.1572 - accuracy: 0.9996 - false_positives: 0.6164 - val_loss: 1.7293 - val_accuracy: 0.5469 - val_false_positives: 209.0000\n",
            "Epoch 91/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.1557 - accuracy: 0.9999 - false_positives: 0.2603 - val_loss: 1.8033 - val_accuracy: 0.5451 - val_false_positives: 225.0000\n",
            "Epoch 92/100\n",
            "72/72 [==============================] - 42s 537ms/step - loss: 0.1526 - accuracy: 0.9994 - false_positives: 0.3836 - val_loss: 1.7043 - val_accuracy: 0.5590 - val_false_positives: 211.0000\n",
            "Epoch 93/100\n",
            "72/72 [==============================] - 42s 536ms/step - loss: 0.1507 - accuracy: 0.9998 - false_positives: 0.3973 - val_loss: 1.6883 - val_accuracy: 0.5712 - val_false_positives: 200.0000\n",
            "Epoch 94/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.1496 - accuracy: 0.9986 - false_positives: 2.3014 - val_loss: 1.7687 - val_accuracy: 0.5365 - val_false_positives: 228.0000\n",
            "Epoch 95/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.1591 - accuracy: 0.9978 - false_positives: 3.1096 - val_loss: 1.7387 - val_accuracy: 0.5747 - val_false_positives: 205.0000\n",
            "Epoch 96/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.1592 - accuracy: 0.9978 - false_positives: 1.8630 - val_loss: 1.7731 - val_accuracy: 0.5712 - val_false_positives: 197.0000\n",
            "Epoch 97/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.1535 - accuracy: 0.9978 - false_positives: 2.5753 - val_loss: 1.6701 - val_accuracy: 0.5851 - val_false_positives: 194.0000\n",
            "Epoch 98/100\n",
            "72/72 [==============================] - 42s 535ms/step - loss: 0.1487 - accuracy: 0.9993 - false_positives: 1.0548 - val_loss: 1.7045 - val_accuracy: 0.5590 - val_false_positives: 206.0000\n",
            "Epoch 99/100\n",
            "72/72 [==============================] - 42s 534ms/step - loss: 0.1501 - accuracy: 0.9978 - false_positives: 1.0000 - val_loss: 1.7234 - val_accuracy: 0.5660 - val_false_positives: 213.0000\n",
            "Epoch 100/100\n",
            "72/72 [==============================] - 42s 532ms/step - loss: 0.1586 - accuracy: 0.9954 - false_positives: 3.7123 - val_loss: 1.8689 - val_accuracy: 0.5503 - val_false_positives: 223.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlh8lxRevAje"
      },
      "source": [
        "# Training with machine learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr6YdeGpv8La"
      },
      "source": [
        "def getDatasetForMachineLearning(train_set, test_set, trainOutput = 1, testOutput = 1):\n",
        "  train_X = []\n",
        "  train_Y = []\n",
        "  test_X = []\n",
        "  test_Y = []\n",
        "\n",
        "  setTrainY = []\n",
        "  setTestY = []\n",
        "\n",
        "  y_doubles = []\n",
        "\n",
        "\n",
        "  # for element in list(test_set.as_numpy_iterator()):\n",
        "  #   for className in element[1]:\n",
        "\n",
        "\n",
        "\n",
        "  for element in list(train_set.as_numpy_iterator()):\n",
        "    for className in element[1]:\n",
        "      train_Y.append(np.argmax(className, axis=-1))\n",
        "    for features in element[0]:\n",
        "      train_X.append(features)  \n",
        "  for element in list(test_set.as_numpy_iterator()):\n",
        "    for className in element[1]:\n",
        "      test_Y.append(np.argmax(className, axis=-1))\n",
        "    for features in element[0]:\n",
        "      test_X.append(features)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  train_Y = np.array(train_Y)\n",
        "  test_Y = np.array(test_Y)\n",
        "  train_X = np.array(train_X)\n",
        "  test_X = np.array(test_X)\n",
        "\n",
        "  return train_X, train_Y, test_X, test_Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOId3OzNwAkn"
      },
      "source": [
        "def classifyWithMachineLearning(train_set, test_set, cnn_path):\n",
        "    from keras.models import Model\n",
        "    from keras.models import load_model\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    from sklearn.neural_network import MLPClassifier\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "    from sklearn.svm import SVC\n",
        "    from sklearn.naive_bayes import GaussianNB\n",
        "    from sklearn.ensemble import GradientBoostingClassifier\n",
        "    from sklearn.ensemble import AdaBoostClassifier\n",
        "    from sklearn.svm import LinearSVC\n",
        "    import pickle\n",
        "    import cv2\n",
        "  \n",
        "\n",
        "    train_X, train_Y, test_X, test_Y = getDatasetForMachineLearning(train_set, test_set)\n",
        "\n",
        "\n",
        "\n",
        "    random_state = 100\n",
        "\n",
        "    cnn = load_model(cnn_path)\n",
        "    outputLayer = cnn.layers[-5] # Dense layer 512.\n",
        "    \n",
        "\n",
        "    intermediate_layer_model = Model(inputs=cnn.input,\n",
        "                                    outputs=outputLayer.output)\n",
        "    \n",
        "    train_output = intermediate_layer_model.predict(train_X)\n",
        "    #print(train_output)\n",
        "    train_output = np.array(train_output)\n",
        "\n",
        "\n",
        "    test_output = intermediate_layer_model.predict(test_X)\n",
        "    #print(test_output)\n",
        "    test_output = np.array(test_output)\n",
        "    \n",
        "    models=[MLPClassifier(max_iter=200000, activation='tanh',solver='lbfgs', random_state=random_state),\n",
        "            LogisticRegression(dual=False,multi_class='auto',solver='lbfgs',random_state=random_state),\n",
        "            RandomForestClassifier(n_estimators=100,criterion='entropy'),\n",
        "            LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto'),\n",
        "            KNeighborsClassifier(n_neighbors=10, weights='distance'),\n",
        "            SVC(kernel='poly',degree=2,C=100, gamma='auto'),\n",
        "            GaussianNB(),\n",
        "            GradientBoostingClassifier(),\n",
        "            AdaBoostClassifier(),\n",
        "            LinearSVC(penalty='l1',dual=False,multi_class='crammer_singer',max_iter=1000000),\n",
        "            SVC(kernel='rbf', random_state=0, gamma=.01, C=100000)]\n",
        "\n",
        "\n",
        "\n",
        "    # model = models[4].fit(train_output, train_Y)   \n",
        "    # model.predict(test_output)\n",
        "    # result = model.score(test_output, test_Y)  \n",
        "    # result2 = model.score(train_output, train_Y)      \n",
        "    # print(\"Test Set Accuracy: \" + str(result))\n",
        "    # print(\"Train Set Accuracy: \" + str(result2))\n",
        "\n",
        "    \n",
        "\n",
        "    model_list = []\n",
        "\n",
        "    for i in range(len(models)):\n",
        "        print(\"\\n\\nModel\" + str(i) + \":\" + str(models[i]))\n",
        "        model = models[i].fit(train_output, train_Y)  # Bad input shape: 1, 3, 5, 6, 7, 8, 9, 10 \n",
        "        model_list.append(model)\n",
        "\n",
        "        testResult = model.score(test_output, test_Y)  \n",
        "        trainResult = model.score(train_output, train_Y) \n",
        "        yPredicted = model.predict(test_output)\n",
        "        confMatrix = confusion_matrix(test_Y, yPredicted)\n",
        "\n",
        "        print(confMatrix)\n",
        "        print(\"Test Set Accuracy: \" + str(testResult))\n",
        "        print(\"Train Set Accuracy: \" + str(trainResult))\n",
        "\n",
        "    return model_list\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91hYZk6sxEdk",
        "outputId": "aa8b68a3-0e9b-4a83-c2f9-db8cb06c7ba7"
      },
      "source": [
        "train_set, test_set = getDataset(log_augNormal_path, seed=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2880 files belonging to 8 classes.\n",
            "Using 2304 files for training.\n",
            "Found 2880 files belonging to 8 classes.\n",
            "Using 576 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "parLBCTTwGj5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b951fb97-1045-4ce2-ea16-971eb7ad839e"
      },
      "source": [
        "#model = trainCustomCNN3(train_set, test_set)\n",
        "# print((list(train_set.as_numpy_iterator())[35][1]))\n",
        "\n",
        "\n",
        "ml_models = classifyWithMachineLearning(train_set, test_set, \n",
        "                            cnn_path=\"/content/drive/MyDrive/colab/final_project/models/seed100/log_specAugment.h5\")\n",
        "\n",
        "\n",
        "######################### SEEDLER AYNI VERILMELI #####################\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Model0:MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
            "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
            "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
            "              learning_rate_init=0.001, max_fun=15000, max_iter=200000,\n",
            "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
            "              power_t=0.5, random_state=100, shuffle=True, solver='lbfgs',\n",
            "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
            "              warm_start=False)\n",
            "[[22  5  1  4  0  1  1  2]\n",
            " [ 8 58  1  4  0  0  1  0]\n",
            " [ 0  6 51  5  5  5  5  1]\n",
            " [12  1  1 43  1  3  5  2]\n",
            " [ 2  0  0  3 59  1 13  4]\n",
            " [ 5  4  6  7  1 66  0  2]\n",
            " [ 1  0  1  1  3  0 72  0]\n",
            " [ 3  0  7  0  0  3  5 53]]\n",
            "Test Set Accuracy: 0.7361111111111112\n",
            "Train Set Accuracy: 1.0\n",
            "\n",
            "\n",
            "Model1:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[26  5  3  2  0  0  0  0]\n",
            " [ 1 70  0  1  0  0  0  0]\n",
            " [ 2  1 63  0  4  3  3  2]\n",
            " [ 2  4  5 53  0  3  1  0]\n",
            " [ 1  1  0  1 72  0  5  2]\n",
            " [ 0  5  6  4  1 74  0  1]\n",
            " [ 0  1  0  1  3  0 72  1]\n",
            " [ 0  0  1  0  0  0  2 68]]\n",
            "Test Set Accuracy: 0.8645833333333334\n",
            "Train Set Accuracy: 1.0\n",
            "\n",
            "\n",
            "Model2:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='entropy', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "[[19  9  2  5  0  0  1  0]\n",
            " [ 0 70  1  0  0  1  0  0]\n",
            " [ 0  0 56  2  3  7  4  6]\n",
            " [ 1  6  6 47  0  5  2  1]\n",
            " [ 0  1  3  2 66  0  6  4]\n",
            " [ 0  4  4  5  2 74  0  2]\n",
            " [ 0  1  1  3  2  1 69  1]\n",
            " [ 0  0  3  0  0  0  2 66]]\n",
            "Test Set Accuracy: 0.8107638888888888\n",
            "Train Set Accuracy: 1.0\n",
            "\n",
            "\n",
            "Model3:LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage='auto',\n",
            "                           solver='eigen', store_covariance=False, tol=0.0001)\n",
            "[[26  5  3  2  0  0  0  0]\n",
            " [ 0 70  0  1  0  0  1  0]\n",
            " [ 1  1 61  0  2  5  3  5]\n",
            " [ 1  6  5 48  2  4  1  1]\n",
            " [ 0  1  2  0 72  0  5  2]\n",
            " [ 0  5  4  4  2 76  0  0]\n",
            " [ 0  0  0  0  4  0 72  2]\n",
            " [ 0  0  1  0  0  1  4 65]]\n",
            "Test Set Accuracy: 0.8506944444444444\n",
            "Train Set Accuracy: 1.0\n",
            "\n",
            "\n",
            "Model4:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
            "                     weights='distance')\n",
            "[[27  5  2  2  0  0  0  0]\n",
            " [ 1 71  0  0  0  0  0  0]\n",
            " [ 3  1 65  0  3  0  3  3]\n",
            " [ 5  5  1 49  1  3  2  2]\n",
            " [ 2  1  0  1 72  0  3  3]\n",
            " [ 0  4  7  4  1 72  0  3]\n",
            " [ 0  2  0  0  4  0 71  1]\n",
            " [ 0  0  3  0  0  0  2 66]]\n",
            "Test Set Accuracy: 0.8559027777777778\n",
            "Train Set Accuracy: 1.0\n",
            "\n",
            "\n",
            "Model5:SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=2, gamma='auto', kernel='poly',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n",
            "[[25  6  2  2  0  0  1  0]\n",
            " [ 2 69  0  1  0  0  0  0]\n",
            " [ 2  1 64  0  3  3  3  2]\n",
            " [ 4  4  3 54  0  2  1  0]\n",
            " [ 0  1  0  1 73  0  5  2]\n",
            " [ 0  4  6  3  1 77  0  0]\n",
            " [ 0  0  0  1  2  0 75  0]\n",
            " [ 0  0  1  0  0  0  2 68]]\n",
            "Test Set Accuracy: 0.8767361111111112\n",
            "Train Set Accuracy: 1.0\n",
            "\n",
            "\n",
            "Model6:GaussianNB(priors=None, var_smoothing=1e-09)\n",
            "[[27  6  0  3  0  0  0  0]\n",
            " [ 3 68  0  1  0  0  0  0]\n",
            " [ 4  2 52  2  4  7  4  3]\n",
            " [ 5  5  2 50  1  3  1  1]\n",
            " [ 1  3  1  3 55  1 14  4]\n",
            " [ 1  5  4  7  2 71  0  1]\n",
            " [ 0  0  0  2  4  0 72  0]\n",
            " [ 0  0  1  0  0  2  2 66]]\n",
            "Test Set Accuracy: 0.8003472222222222\n",
            "Train Set Accuracy: 0.9991319444444444\n",
            "\n",
            "\n",
            "Model7:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
            "                           max_features=None, max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=1, min_samples_split=2,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                           n_iter_no_change=None, presort='deprecated',\n",
            "                           random_state=None, subsample=1.0, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "[[21  6  4  2  0  0  1  2]\n",
            " [ 2 62  0  5  0  1  2  0]\n",
            " [ 3  0 61  0  4  5  3  2]\n",
            " [ 1  5  5 47  1  6  2  1]\n",
            " [ 0  3  2  1 68  0  5  3]\n",
            " [ 2  5  5  9  2 63  1  4]\n",
            " [ 0  3  2  1  6  0 65  1]\n",
            " [ 0  0  3  1  1  1  3 62]]\n",
            "Test Set Accuracy: 0.7795138888888888\n",
            "Train Set Accuracy: 1.0\n",
            "\n",
            "\n",
            "Model8:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
            "                   n_estimators=50, random_state=None)\n",
            "[[ 8  4 11 10  0  1  2  0]\n",
            " [ 1 44  8 16  0  0  3  0]\n",
            " [ 0  2 51 10  2  4  1  8]\n",
            " [ 0  1  7 53  0  4  1  2]\n",
            " [ 0  0  7  4 49  1 10 11]\n",
            " [ 0  1 15 17  4 46  1  7]\n",
            " [ 1  1  2  7  4  2 58  3]\n",
            " [ 0  0 16  0  1  3  7 44]]\n",
            "Test Set Accuracy: 0.6128472222222222\n",
            "Train Set Accuracy: 0.9535590277777778\n",
            "\n",
            "\n",
            "Model9:LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000000,\n",
            "          multi_class='crammer_singer', penalty='l1', random_state=None,\n",
            "          tol=0.0001, verbose=0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[26  5  3  2  0  0  0  0]\n",
            " [ 2 68  1  0  0  0  1  0]\n",
            " [ 2  0 65  0  4  2  3  2]\n",
            " [ 2  3  5 53  1  3  1  0]\n",
            " [ 1  1  1  1 71  0  5  2]\n",
            " [ 0  5  4  3  2 76  0  1]\n",
            " [ 0  1  0  1  4  0 72  0]\n",
            " [ 0  0  1  0  0  0  2 68]]\n",
            "Test Set Accuracy: 0.8663194444444444\n",
            "Train Set Accuracy: 1.0\n",
            "\n",
            "\n",
            "Model10:SVC(C=100000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=0, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n",
            "[[19  9  1  6  0  0  1  0]\n",
            " [ 1 69  0  2  0  0  0  0]\n",
            " [ 3  2 62  1  2  2  4  2]\n",
            " [ 1  6  4 54  0  2  1  0]\n",
            " [ 1  1  1  4 66  1  7  1]\n",
            " [ 0  5  5  3  1 77  0  0]\n",
            " [ 0  0  1  1  1  0 74  1]\n",
            " [ 0  0  1  1  0  1  3 65]]\n",
            "Test Set Accuracy: 0.84375\n",
            "Train Set Accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9oLimFzML8x"
      },
      "source": [
        "import pickle\n",
        "\n",
        "ml_models_dict = {\n",
        "        0: \"MLPClassifier\",\n",
        "        1: \"LogisticRegression\",\n",
        "        2: \"RandomForestClassifier\",\n",
        "        3: \"LinearDiscriminantAnalysis\",\n",
        "        4: \"KNeighborsClassifier\",\n",
        "        5: \"SVC_Polynomial_Kernel\",\n",
        "        6: \"GaussianNB\",\n",
        "        7: \"GradientBoostingClassifier\",\n",
        "        8: \"AdaBoostClassifier\",\n",
        "        9: \"LinearSVC\",\n",
        "        10: \"SVC_RBF_Kernel\"\n",
        "    }\n",
        "\n",
        "for i in range(len(ml_models)):\n",
        "    pickle.dump(ml_models[i], open(\"./models/ml_models/seed100/\" + ml_models_dict[i] + \".sav\", 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_cawO9x2vCO"
      },
      "source": [
        "# CNN Model Stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq0F1hTs83qj",
        "outputId": "3e097533-c16a-4aa5-c7a4-69ffa06bd4d3"
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "_, test_set = getDataset(log_path, seed=50)\n",
        "model = keras.models.load_model(\"/content/drive/MyDrive/colab/final_project/models/seed50/log_original.h5\")\n",
        "\n",
        "# print(test_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1440 files belonging to 8 classes.\n",
            "Using 1152 files for training.\n",
            "Found 1440 files belonging to 8 classes.\n",
            "Using 288 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ksIkKCz2uoN",
        "outputId": "6c37b71d-1195-47fb-9c18-2b1dc7181e30"
      },
      "source": [
        "predictions = np.array([])\n",
        "labels =  np.array([])\n",
        "for x, y in test_set:\n",
        "    predictions = np.concatenate([predictions, model.predict_classes(x)])\n",
        "    labels = np.concatenate([labels, np.argmax(y.numpy(), axis=-1)])\n",
        "\n",
        "\n",
        "print(\"Acc:\", metrics.accuracy_score(labels, predictions))\n",
        "\n",
        "\n",
        "confusion_mat = metrics.confusion_matrix(labels, predictions)\n",
        "print(confusion_mat)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Acc: 0.6701388888888888\n",
            "[[ 8  8  0  2  0  0  0  1]\n",
            " [ 3 29  0  4  0  1  0  0]\n",
            " [ 3  0 17  0 10  3  3  1]\n",
            " [ 3  2  5 20  1  2  3  1]\n",
            " [ 0  1  2  0 34  1  2  1]\n",
            " [ 0  1  4  3  1 30  0  4]\n",
            " [ 1  3  1  3  0  0 27  1]\n",
            " [ 1  3  2  0  1  2  1 28]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC4WyM2IHonL"
      },
      "source": [
        "# Visualisation of CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejvO4_sLHZtC",
        "outputId": "6d884cfb-74b6-40c4-f70d-eb6f14d2c5f5"
      },
      "source": [
        "!pip install visualkeras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting visualkeras\n",
            "  Downloading https://files.pythonhosted.org/packages/a5/93/abd375b37add77d58a8c48a506ae39bb77c4380e2507ea444325ff1b9971/visualkeras-0.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from visualkeras) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from visualkeras) (1.19.5)\n",
            "Collecting aggdraw>=1.3.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/ca/440addbccb916f7f68a78484eff953917c59fc2e41b2440f9be327742e39/aggdraw-1.3.12-cp37-cp37m-manylinux2010_x86_64.whl (795kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 9.6MB/s \n",
            "\u001b[?25hInstalling collected packages: aggdraw, visualkeras\n",
            "Successfully installed aggdraw-1.3.12 visualkeras-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "jPzRkksOHOIA",
        "outputId": "e197688a-abee-4a3d-e80c-eae64eec52ce"
      },
      "source": [
        "import visualkeras\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model(\"/content/drive/MyDrive/colab/final_project/models/seed100/log_specAugment.h5\")\n",
        "\n",
        "visualkeras.layered_view(model).show() # display using your system viewer\n",
        "visualkeras.layered_view(model, to_file='output.png') # write to disk\n",
        "visualkeras.layered_view(model, to_file='output.png').show() # write and show\n",
        "\n",
        "visualkeras.layered_view(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGBA size=1069x683 at 0x7F0960210C90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    }
  ]
}